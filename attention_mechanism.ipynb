{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPw+Tv1XVPFmzIzng2HuEoe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbourke/learn-transformers/blob/main/attention_mechanism.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [WIP] Attention mechanism\n",
        "\n",
        "**Focus:** Build intuition to build up to replicating the original Transformer paper.\n",
        "\n",
        "### This notebook\n",
        "\n",
        "* Recreate self-attention as per Transformer paper\n",
        "* Recreate multi-head attention as per Transformer paper\n",
        "\n",
        "### Later\n",
        "* Recreate Transformer model architecture\n",
        "* Train on a simple example\n",
        "\n",
        "Sources:\n",
        "\n",
        "* Transformer paper: https://arxiv.org/abs/1706.03762\n",
        "* The annotated transformer: http://nlp.seas.harvard.edu/2018/04/01/attention.html\n",
        "* https://lilianweng.github.io/posts/2018-06-24-attention/#self-attention\n",
        "* https://jaykmody.com/blog/attention-intuition/\n",
        "* Compact transformers - https://medium.com/pytorch/training-compact-transformers-from-scratch-in-30-minutes-with-pytorch-ff5c21668ed5\n",
        "* Implemented MHA - https://nn.labml.ai/transformers/mha.html"
      ],
      "metadata": {
        "id": "usdE3sRsGnj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What we're going to do\n",
        "\n",
        "Replicate:\n",
        "* PyTorch's `scaled_dot_product_attention` - https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html\n",
        "* PyTorch's MultiHeadAttention - https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html"
      ],
      "metadata": {
        "id": "b5lKkczcnUaI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6-XaYYv9GcKP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple scaled-dot-product-attention (no mask)\n",
        "\n",
        "TK:\n",
        "- Can I replicate this in Google Sheets?... yes I can... kind of (except for softmax, etc)\n",
        "- Turn this function into the same format as the transformer paper (e.g. figure 2)"
      ],
      "metadata": {
        "id": "RvO_nyA2O6tZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def attention(query, key, value):\n",
        "  d_k = torch.tensor(query.shape[-1]) # torch.sqrt needs a tensor\n",
        "  q_k = F.softmax(torch.matmul(query, key.T)/torch.sqrt(d_k), dim=-1)\n",
        "  return torch.matmul(q_k, value.T)"
      ],
      "metadata": {
        "id": "nMVXnybZGhun"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "x = torch.randn(10, 10)\n",
        "\n",
        "attention(query=x, key=x, value=x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWgiQ8HWHjcK",
        "outputId": "c3e5a132-1b44-412c-f77c-33b11d88be87"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.8933, -0.3887, -0.7377, -0.2461, -1.5391,  0.0764, -0.0861, -1.0471,\n",
              "          0.0089,  0.1876],\n",
              "        [ 0.4219, -0.7769,  0.8384,  0.3348,  0.0515,  0.2086,  1.2753,  0.2287,\n",
              "         -0.2691, -0.0226],\n",
              "        [ 0.4126, -0.0101,  0.7777, -0.7219, -0.8859, -0.6319,  0.0446, -0.0064,\n",
              "         -0.4851, -0.0692],\n",
              "        [-0.5196, -0.3668,  1.1495, -0.2994, -0.7661,  0.0208,  1.2501,  0.0915,\n",
              "         -0.0215,  0.3415],\n",
              "        [ 0.2543, -0.6703,  1.2743, -0.2598, -1.0734, -0.5371,  1.3273,  0.0430,\n",
              "          0.4069,  0.1190],\n",
              "        [-0.1206,  0.2336,  0.8385,  0.4162,  0.3648, -0.2610,  0.5973, -0.0789,\n",
              "          0.2875,  0.0406],\n",
              "        [-0.0315,  1.2026,  0.6622,  0.0972, -1.1233, -1.1447,  1.7388,  0.3997,\n",
              "          0.6841, -0.7225],\n",
              "        [-0.6842, -0.1752,  1.0953, -0.3012, -0.6531, -0.2085,  0.7526, -0.3217,\n",
              "         -0.1753,  0.0630],\n",
              "        [-0.0737, -0.3024,  0.6222,  0.0706, -0.5312, -0.0393,  0.9918, -0.3184,\n",
              "         -0.1715,  0.0771],\n",
              "        [ 0.2698,  0.1422,  0.6674,  0.0506, -0.0081, -0.1161,  0.3864, -0.2013,\n",
              "          0.1447,  0.1315]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.size(-1)"
      ],
      "metadata": {
        "id": "iPUm3PTpHnhN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fecb1d5-0d3e-4613-db64-56ef691dba09"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO: What is a query, key and value?\n",
        "\n",
        "* What if I told you you already know about the attention mechanism?... and your local cafe owner knows it very well\n",
        "\n",
        "* Give an example of different values input and output into our attention mechansim\n",
        "\n",
        "TK - Can I do sales of different products? Does this relate?\n",
        "\n",
        "E.g. query = sales on monday, key = product, value = amount? Does this work?"
      ],
      "metadata": {
        "id": "0Kxahii5xJRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: finalize this and upload it to GitHub (if it works)\n",
        "!wget https://www.dropbox.com/s/8heqlnrpkf7tlbq/cafe_sales_data_csv.xlsx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VbBzoBOxLj_",
        "outputId": "ab248644-6999-443b-cec7-984174b66947"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-15 02:04:39--  https://www.dropbox.com/s/8heqlnrpkf7tlbq/cafe_sales_data_csv.xlsx\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:6019:18::a27d:412\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/8heqlnrpkf7tlbq/cafe_sales_data_csv.xlsx [following]\n",
            "--2023-06-15 02:04:39--  https://www.dropbox.com/s/raw/8heqlnrpkf7tlbq/cafe_sales_data_csv.xlsx\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc01ae19670285c4629e720f7d48.dl.dropboxusercontent.com/cd/0/inline/B-B-924nGYpqljzKg6GwlYvXRrjX-ken-dip4NKl69M7OykayeTtigY3CYtyYQxtiFM0m2tTtDXoZbelxnvwjFqUzAnDafSzt4aAuGRYQSAbvQFhnE8Oh05oMU1-K1wkWvQ7N0HL9elxln9OEDMc_zsxtgxhgDcTxlWRCmmpSNNUSA/file# [following]\n",
            "--2023-06-15 02:04:40--  https://uc01ae19670285c4629e720f7d48.dl.dropboxusercontent.com/cd/0/inline/B-B-924nGYpqljzKg6GwlYvXRrjX-ken-dip4NKl69M7OykayeTtigY3CYtyYQxtiFM0m2tTtDXoZbelxnvwjFqUzAnDafSzt4aAuGRYQSAbvQFhnE8Oh05oMU1-K1wkWvQ7N0HL9elxln9OEDMc_zsxtgxhgDcTxlWRCmmpSNNUSA/file\n",
            "Resolving uc01ae19670285c4629e720f7d48.dl.dropboxusercontent.com (uc01ae19670285c4629e720f7d48.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:6019:15::a27d:40f\n",
            "Connecting to uc01ae19670285c4629e720f7d48.dl.dropboxusercontent.com (uc01ae19670285c4629e720f7d48.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B-BRJNmQ7pl3MvIuUzQSLx8AMCp6Qt6m5QQOQD967Pk3_tl5HEgkYYxbECxHdUCz-cZgkBl3yGU_SRwJZizXSt_vM4EPDOcpfiZJe2xs19eNkklb74TLLjI-zqgmxIVL8m5ESMyRtSL4yi9XJDDTysqE4SWbZOBMdwOGf_OVLqWBBCJAL3XIHZQC2AejVkfipURinzoK_ScgE6GZc65pGvzQw1QRcfm2r0fMJeIhErgEUfCceYyk6lmExnzka62uJsGOvVsoYQt2M-suGTXW3aRruZZZt5xEcf_zWbxA20dTAh04OaWeog_ZdggbvV3gfKXIFko3QaGTB-px8zUNeeTm9YXkhSFAEzIban_4TKFrWjT2cTExtWhsPl7L1XnuurjrBDeZDeitv2nTLZDZ4rNHn_HfiQNU0DukNGhD-fCEJA/file [following]\n",
            "--2023-06-15 02:04:40--  https://uc01ae19670285c4629e720f7d48.dl.dropboxusercontent.com/cd/0/inline2/B-BRJNmQ7pl3MvIuUzQSLx8AMCp6Qt6m5QQOQD967Pk3_tl5HEgkYYxbECxHdUCz-cZgkBl3yGU_SRwJZizXSt_vM4EPDOcpfiZJe2xs19eNkklb74TLLjI-zqgmxIVL8m5ESMyRtSL4yi9XJDDTysqE4SWbZOBMdwOGf_OVLqWBBCJAL3XIHZQC2AejVkfipURinzoK_ScgE6GZc65pGvzQw1QRcfm2r0fMJeIhErgEUfCceYyk6lmExnzka62uJsGOvVsoYQt2M-suGTXW3aRruZZZt5xEcf_zWbxA20dTAh04OaWeog_ZdggbvV3gfKXIFko3QaGTB-px8zUNeeTm9YXkhSFAEzIban_4TKFrWjT2cTExtWhsPl7L1XnuurjrBDeZDeitv2nTLZDZ4rNHn_HfiQNU0DukNGhD-fCEJA/file\n",
            "Reusing existing connection to uc01ae19670285c4629e720f7d48.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5101 (5.0K) [application/vnd.openxmlformats-officedocument.spreadsheetml.sheet]\n",
            "Saving to: ‘cafe_sales_data_csv.xlsx’\n",
            "\n",
            "cafe_sales_data_csv 100%[===================>]   4.98K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-15 02:04:40 (1.43 GB/s) - ‘cafe_sales_data_csv.xlsx’ saved [5101/5101]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel(\"cafe_sales_data_csv.xlsx\") # TODO: read_excel with _csv in the filename is confusing...\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "p-wiDpW9xgVo",
        "outputId": "6f693a28-d56e-4959-b80f-b26304d4766f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Unnamed: 0  Monday  Tuesday  Wednesday  Thursday  Friday  Saturday  Sunday\n",
              "0     Coffee       0       50         55        68      91       107      84\n",
              "1      Bread       0       20         22        25      12        40      49\n",
              "2      Bacon       0       10         15        20      10        65      39\n",
              "3       Milk       0       15         15        18      16        51      45\n",
              "4      Bagel       0       21          8        20      60        56      44\n",
              "5   Sandwich       0        9          8        50      18        62      50\n",
              "6  Crossiant       0       11          4         3       7        49      55"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ac2cd2c-b80e-49d4-a6aa-d6a1dff32f9e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Monday</th>\n",
              "      <th>Tuesday</th>\n",
              "      <th>Wednesday</th>\n",
              "      <th>Thursday</th>\n",
              "      <th>Friday</th>\n",
              "      <th>Saturday</th>\n",
              "      <th>Sunday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Coffee</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>55</td>\n",
              "      <td>68</td>\n",
              "      <td>91</td>\n",
              "      <td>107</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bread</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>22</td>\n",
              "      <td>25</td>\n",
              "      <td>12</td>\n",
              "      <td>40</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bacon</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>65</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Milk</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>16</td>\n",
              "      <td>51</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bagel</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>60</td>\n",
              "      <td>56</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Sandwich</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>50</td>\n",
              "      <td>18</td>\n",
              "      <td>62</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Crossiant</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>49</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ac2cd2c-b80e-49d4-a6aa-d6a1dff32f9e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ac2cd2c-b80e-49d4-a6aa-d6a1dff32f9e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ac2cd2c-b80e-49d4-a6aa-d6a1dff32f9e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create price vector\n",
        "price_dict = {\n",
        "    \"coffee\": 5,\n",
        "    \"bread\": 8,\n",
        "    \"bacon\": 15,\n",
        "    \"milk\": 4,\n",
        "    \"bagel\": 9,\n",
        "    \"sandwich\": 12,\n",
        "    \"croissant\": 8\n",
        "}\n",
        "price_vector = torch.tensor(list(price_dict.values()), dtype=torch.float32)\n",
        "price_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o-GJZj-zWsg",
        "outputId": "6077188d-7aa2-4b73-c53e-41997e2ac71c"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5.,  8., 15.,  4.,  9., 12.,  8.])"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sales matrix\n",
        "sales_matrix = torch.tensor(df.drop(\"Unnamed: 0\", axis=1).values, dtype=torch.float32)\n",
        "sales_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLZgRl5Dz51v",
        "outputId": "e5c5082d-aaf0-4964-deb4-118f5438852b"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0.,  50.,  55.,  68.,  91., 107.,  84.],\n",
              "        [  0.,  20.,  22.,  25.,  12.,  40.,  49.],\n",
              "        [  0.,  10.,  15.,  20.,  10.,  65.,  39.],\n",
              "        [  0.,  15.,  15.,  18.,  16.,  51.,  45.],\n",
              "        [  0.,  21.,   8.,  20.,  60.,  56.,  44.],\n",
              "        [  0.,   9.,   8.,  50.,  18.,  62.,  50.],\n",
              "        [  0.,  11.,   4.,   3.,   7.,  49.,  55.]])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Sales: {sales_matrix.shape} (seven products, seven days of week)\")\n",
        "print(f\"Prices: {price_vector.shape} (seven products)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S_HxbAn0dQ9",
        "outputId": "961dcf7f-0557-4639-f8ef-f641d601ba42"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sales: torch.Size([7, 7]) (seven products, seven days of week)\n",
            "Prices: torch.Size([7]) (seven products)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the sales per day\n",
        "price_vector.matmul(sales_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5FLeA5Z0HIa",
        "outputId": "04f28c32-346a-4d94-acec-16a646e53e1e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   0, 1005,  936, 1716, 1577, 3674, 3013])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find item sales per week\n",
        "price_vector.matmul(sales_matrix[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-zqTmpc1CrJ",
        "outputId": "b93edce0-4ff6-420c-ca54-0be394cac6c1"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4272)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sales_per_item = (price_vector * sales_matrix.T).T\n",
        "sales_per_item"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVAyGUxf1Gjh",
        "outputId": "4fa03373-2863-441f-b306-e9a73a47e751"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0, 250, 275, 340, 455, 535, 420],\n",
              "        [  0, 160, 176, 200,  96, 320, 392],\n",
              "        [  0, 150, 225, 300, 150, 975, 585],\n",
              "        [  0,  60,  60,  72,  64, 204, 180],\n",
              "        [  0, 189,  72, 180, 540, 504, 396],\n",
              "        [  0, 108,  96, 600, 216, 744, 600],\n",
              "        [  0,  88,  32,  24,  56, 392, 440]])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(sales_per_item, dim=1).T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQCDo0BX4H7r",
        "outputId": "674f30a8-81b0-4687-d1ab-689a71ebb7ed"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2275, 1344, 2385,  640, 1881, 2364, 1032])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "price_vector * sales_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKv7H4u05sJq",
        "outputId": "04a344f7-7734-418a-9d6d-846cf376ed46"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   0,  400,  825,  272,  819, 1284,  672],\n",
              "        [   0,  160,  330,  100,  108,  480,  392],\n",
              "        [   0,   80,  225,   80,   90,  780,  312],\n",
              "        [   0,  120,  225,   72,  144,  612,  360],\n",
              "        [   0,  168,  120,   80,  540,  672,  352],\n",
              "        [   0,   72,  120,  200,  162,  744,  400],\n",
              "        [   0,   88,   60,   12,   63,  588,  440]])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "price_vector.unsqueeze(0).T * sales_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycUpMtzo3rM2",
        "outputId": "e860ac36-3651-45e5-9702-3114664183e1"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0, 250, 275, 340, 455, 535, 420],\n",
              "        [  0, 160, 176, 200,  96, 320, 392],\n",
              "        [  0, 150, 225, 300, 150, 975, 585],\n",
              "        [  0,  60,  60,  72,  64, 204, 180],\n",
              "        [  0, 189,  72, 180, 540, 504, 396],\n",
              "        [  0, 108,  96, 600, 216, 744, 600],\n",
              "        [  0,  88,  32,  24,  56, 392, 440]])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.dot(price_vector, sales_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jK8dxkx5455M",
        "outputId": "511c4a1a-fad2-4d3e-c8d3-60b48d62a396"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0, 1005,  936, 1716, 1577, 3674, 3013])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "price_vector.unsqueeze(0).matmul(sales_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1H1DfK034mj",
        "outputId": "24f74b3c-1bea-46b9-9c17-f1ce5a5dbc56"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   0, 1005,  936, 1716, 1577, 3674, 3013]])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TK - try create an example for attention"
      ],
      "metadata": {
        "id": "lA8p_lGV6H6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a query (\"What are the sales on Wednesday?\")\n",
        "sales_on_wednesday_vector = torch.zeros(7) # days of week\n",
        "sales_on_wednesday_vector[2] = 1\n",
        "sales_on_wednesday_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SriEVG8E7B0I",
        "outputId": "f79b0b3e-92a3-4886-9e27-b1aad6dcf472"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 1., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the sales matrix (key) to the query (Q * K.T)\n",
        "wednesday_sales = sales_on_wednesday_vector.matmul(sales_matrix.T)\n",
        "wednesday_sales"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO50157P7Bu2",
        "outputId": "7aa75ec3-e423-4fe8-d211-483c3037f51d"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([55., 22., 15., 15.,  8.,  8.,  4.])"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why scale?\n",
        "\n",
        "Watch this... softmax blows it out of the water..."
      ],
      "metadata": {
        "id": "kLGf-DMcByHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(wednesday_sales, dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1pLOP90Bp0T",
        "outputId": "4ae7c6a1-6acd-43b8-e1f0-13b6f2f2975c"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000e+00, 4.6589e-15, 4.2484e-18, 4.2484e-18, 3.8740e-21, 3.8740e-21,\n",
              "        7.0955e-23])"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now scale..."
      ],
      "metadata": {
        "id": "yEgKwEOsB2MN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wednesday_sales.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taUwRq-BB-ew",
        "outputId": "49488737-8626-4138-9c29-174801c15d6c"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([7])"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(wednesday_sales / torch.sqrt(torch.tensor(wednesday_sales.shape[0])), dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIYjdkbcB19e",
        "outputId": "232bfc16-fa8a-40ee-8376-177deb0b9a38"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000e+00, 3.8293e-06, 2.7170e-07, 2.7170e-07, 1.9277e-08, 1.9277e-08,\n",
              "        4.2507e-09])"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Still blown out of the water but better... (could normalize these values first)\n",
        "\n",
        "e.g.\n",
        "\n",
        "```python\n",
        "norm_tensor = (x - torch.min(x))/(torch.max(x) - torch.min(x))\n",
        "```"
      ],
      "metadata": {
        "id": "RTsvFYZKCVGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NEXT:\n",
        "# Try normalizing the tensor values and see how they change/improve stability\n",
        "# Softmax on values with large differences = blows larger values out of the water (e.g. 1.0 vs 1e-10... basically nothing)"
      ],
      "metadata": {
        "id": "kuowdQTzDiAN"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(wednesday_sales / torch.sqrt(torch.tensor(wednesday_sales.shape[0])), dim=0) @ price_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu04zf4YCM9t",
        "outputId": "aea230d2-adaf-45b1-dbb2-07ae972582bb"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.0000)"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Total sales on Wednesday\n",
        "attention_to_pay_on_wednesdays = wednesday_sales @ price_vector # price_vector = value\n",
        "attention_to_pay_on_wednesdays"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuEgA-T46ed1",
        "outputId": "8af10907-538b-47f7-d7a1-721db3fc3c3f"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(936.)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# query = day of week\n",
        "# key = sales per day\n",
        "# value = prices of products\n",
        "# result/output = value of total products sold on target day (how much attention to pay to a certain day)\n",
        "\n",
        "# TK - if you wanted to get more information, you could increase the cafe sales to (52, 7) -> sales per day for 52 weeks in a year\n",
        "# -> or (5, 52, 7) (year, weeks, days) -> sales per day per week for 5 years\n",
        "\n",
        "# TODO:\n",
        "\n",
        "# How does this relate to attention?\n",
        "\n",
        "# At a large enough scale, you can do this for words in sentences.\n",
        "# For example, say we have 100 sentences.\n",
        "# Which words mean the most to which other words?\n",
        "# In a small sample like this, you might be able to design fixed values (like our coffee shop for different products).\n",
        "# But with a larger scale, you might have to design different values for different contexts.\n",
        "# The analogy being in a coffee shop in Australia, your pricing and products might be different to a coffee shop in Africa.\n",
        "# With a large enough corpus of words, having fixed values isn't going to work.\n",
        "# But the principle remains, how important is each other word to another word in a sentence?\n",
        "# What should you do?\n",
        "# Well, you'd never have time to assign a value for each word across a huge corpus.\n",
        "# So you can make the values for each word learnable.\n",
        "# Much like you might adjust your cafe prices and sales events given different days of the week.\n",
        "# The sales on Monday are very low (zero) because your cafe is closed on Monday.\n",
        "# Your customers don't assign much money (or attention) to your cafe on Monday's since they know it's closed.\n",
        "# Much like the attention score for the word \"cat\" might be very low in comparison to the word \"sodium metabisulfite\" because the two hardly ever occur in context of each other.\n",
        "\n",
        "# Why self-attention?\n",
        "\n",
        "# Applying the mechanism to itself over and over for different sequences enables the system to learn from the data itself.\n",
        "# As in, what words keep on showing up in the context of other words?\n",
        "# The dot product/matrix multiplication will amplify larger values.\n",
        "# In essence, given the query \"dog\" and the key of every word in the vocabulary, hopefully the model will learn to return \"cat\" as a likely value and \"sodium metabisulfite\" as a less likely value."
      ],
      "metadata": {
        "id": "7Y5OVpaQ8qJ6"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5mVfO_5m8qFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO: Simple scaled-dot-product-attention (with mask)\n",
        "\n",
        "UPTOHERE:\n",
        "\n",
        "Next:\n",
        "- Read through GPT-from-scratch again\n",
        "- Read through Facebook's xformers\n",
        "- Read through Transformers from scratch blog post\n",
        "\n",
        "--\n",
        "\n",
        "* see: https://jaykmody.com/blog/gpt-from-scratch/#causal\n",
        "* And see: https://github.com/facebookresearch/xformers/blob/main/xformers/components/attention/attention_mask.py\n",
        "  * Default to causal mask: https://github.com/facebookresearch/xformers/blob/97daac83cece6d3d77bb09479777ad6e8ef7dfed/xformers/components/attention/attention_mask.py#LL74C16-L74C16 (`make_causal()`)"
      ],
      "metadata": {
        "id": "2xKawhtOcYfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make causal mask, see: https://jaykmody.com/blog/gpt-from-scratch/#causal\n",
        "additive_mask = torch.triu(\n",
        "    # torch.ones(x.shape[0], x.shape[0]) * float(\"inf\"),\n",
        "    torch.ones(x.shape[0], x.shape[0]) * -1e10, # can use -1e10 to prevent nans\n",
        "    diagonal=1\n",
        ")\n",
        "\n",
        "additive_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-66nS-Rdp0ox",
        "outputId": "9777db3a-8029-4da5-cbdf-79d77e5e457f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000e+00, -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10,\n",
              "         -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10],\n",
              "        [ 0.0000e+00,  0.0000e+00, -1.0000e+10, -1.0000e+10, -1.0000e+10,\n",
              "         -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+10, -1.0000e+10,\n",
              "         -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+10,\n",
              "         -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "         -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00, -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00, -1.0000e+10, -1.0000e+10, -1.0000e+10],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+10, -1.0000e+10],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+10],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def attention_with_mask(query, key, value, mask=None):\n",
        "  d_k = torch.tensor(query.shape[-1]) # torch.sqrt needs a tensor\n",
        "  q_k = torch.matmul(query, key.T) / torch.sqrt(d_k)\n",
        "  print(q_k.shape)\n",
        "\n",
        "\n",
        "  print(f\"q_k: {q_k}\")\n",
        "\n",
        "  # Apply attention mask\n",
        "  if mask is not None:\n",
        "    q_k = q_k + mask\n",
        "\n",
        "  print(f\"q_k with mask: {q_k}\")\n",
        "\n",
        "  # Softmax\n",
        "  attn = F.softmax(q_k, dim=-1)\n",
        "\n",
        "  return torch.matmul(attn, value), attn\n",
        "\n",
        "attention_with_mask(query=x, key=x, value=x, mask=additive_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJcxus6qcYRE",
        "outputId": "0e5bc32a-6e9d-428e-ec59-97cbb2c8711b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 10])\n",
            "q_k: tensor([[ 6.0130e+00, -7.9063e-01, -1.6862e+00, -5.4706e-01, -1.2946e+00,\n",
            "         -1.5651e-01, -9.5597e-01, -1.4247e-01,  4.3972e-01, -5.1831e-01],\n",
            "        [-7.9063e-01,  2.3093e+00, -5.7266e-01,  6.2206e-01,  3.1750e-01,\n",
            "         -9.4774e-01,  1.2001e-01,  1.7332e-01,  1.3094e+00, -7.1141e-01],\n",
            "        [-1.6862e+00, -5.7266e-01,  3.3930e+00,  3.3083e-03,  1.3948e-01,\n",
            "         -2.0294e-01,  2.6444e+00,  1.1129e+00, -1.9716e-01,  2.9590e-01],\n",
            "        [-5.4706e-01,  6.2206e-01,  3.3083e-03,  2.3570e+00,  2.2022e+00,\n",
            "         -6.3796e-01,  1.2451e+00,  7.0473e-01,  8.8856e-01, -9.7713e-01],\n",
            "        [-1.2946e+00,  3.1750e-01,  1.3948e-01,  2.2022e+00,  4.3364e+00,\n",
            "          2.9038e-01, -3.1773e-01,  1.8019e+00,  2.3513e-01, -5.8754e-01],\n",
            "        [-1.5651e-01, -9.4774e-01, -2.0294e-01, -6.3796e-01,  2.9038e-01,\n",
            "          1.7630e+00, -5.9041e-01, -8.1988e-02, -7.1263e-01,  1.0189e+00],\n",
            "        [-9.5597e-01,  1.2001e-01,  2.6444e+00,  1.2451e+00, -3.1773e-01,\n",
            "         -5.9041e-01,  4.7130e+00,  1.3152e+00,  1.0626e+00, -5.1111e-01],\n",
            "        [-1.4247e-01,  1.7332e-01,  1.1129e+00,  7.0473e-01,  1.8019e+00,\n",
            "         -8.1988e-02,  1.3152e+00,  2.9753e+00,  5.4820e-01, -6.4669e-01],\n",
            "        [ 4.3972e-01,  1.3094e+00, -1.9716e-01,  8.8856e-01,  2.3513e-01,\n",
            "         -7.1263e-01,  1.0626e+00,  5.4820e-01,  1.6245e+00, -6.7865e-01],\n",
            "        [-5.1831e-01, -7.1141e-01,  2.9590e-01, -9.7713e-01, -5.8754e-01,\n",
            "          1.0189e+00, -5.1111e-01, -6.4669e-01, -6.7865e-01,  1.0872e+00]])\n",
            "q_k with mask: tensor([[ 6.0130e+00, -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10,\n",
            "         -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10],\n",
            "        [-7.9063e-01,  2.3093e+00, -1.0000e+10, -1.0000e+10, -1.0000e+10,\n",
            "         -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10],\n",
            "        [-1.6862e+00, -5.7266e-01,  3.3930e+00, -1.0000e+10, -1.0000e+10,\n",
            "         -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10],\n",
            "        [-5.4706e-01,  6.2206e-01,  3.3083e-03,  2.3570e+00, -1.0000e+10,\n",
            "         -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10],\n",
            "        [-1.2946e+00,  3.1750e-01,  1.3948e-01,  2.2022e+00,  4.3364e+00,\n",
            "         -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10],\n",
            "        [-1.5651e-01, -9.4774e-01, -2.0294e-01, -6.3796e-01,  2.9038e-01,\n",
            "          1.7630e+00, -1.0000e+10, -1.0000e+10, -1.0000e+10, -1.0000e+10],\n",
            "        [-9.5597e-01,  1.2001e-01,  2.6444e+00,  1.2451e+00, -3.1773e-01,\n",
            "         -5.9041e-01,  4.7130e+00, -1.0000e+10, -1.0000e+10, -1.0000e+10],\n",
            "        [-1.4247e-01,  1.7332e-01,  1.1129e+00,  7.0473e-01,  1.8019e+00,\n",
            "         -8.1988e-02,  1.3152e+00,  2.9753e+00, -1.0000e+10, -1.0000e+10],\n",
            "        [ 4.3972e-01,  1.3094e+00, -1.9716e-01,  8.8856e-01,  2.3513e-01,\n",
            "         -7.1263e-01,  1.0626e+00,  5.4820e-01,  1.6245e+00, -1.0000e+10],\n",
            "        [-5.1831e-01, -7.1141e-01,  2.9590e-01, -9.7713e-01, -5.8754e-01,\n",
            "          1.0189e+00, -5.1111e-01, -6.4669e-01, -6.7865e-01,  1.0872e+00]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345, -0.0431, -1.6047,\n",
              "          -0.7521,  1.6487],\n",
              "         [-0.2925, -1.2790, -0.6577, -0.6261, -0.7064,  0.6764,  1.5697, -0.2219,\n",
              "          -0.5084,  0.4917],\n",
              "         [-0.7351,  1.0349,  0.7731,  1.6162,  1.2376,  1.2712,  0.6256,  1.2893,\n",
              "          -0.2397,  0.0589],\n",
              "         [-0.2166,  0.6004, -1.0463, -0.6979, -0.1510,  1.4382,  0.5008, -0.3120,\n",
              "           0.1167, -0.4545],\n",
              "         [-1.3844,  0.9470, -0.9017, -0.6031, -1.1193,  2.0389, -1.0030, -0.4560,\n",
              "          -0.7730, -0.6367],\n",
              "         [-0.0906,  0.6622, -0.3702,  0.5163, -0.5373, -0.0254, -0.8781, -0.1037,\n",
              "          -0.2517,  0.4371],\n",
              "         [-0.1764,  1.6977, -0.9631,  1.3173,  1.3377,  0.9195,  1.9504,  0.5652,\n",
              "           0.2647, -0.1750],\n",
              "         [-0.8553,  1.1510, -0.3746,  0.3669,  0.0303,  0.8280,  0.4054, -0.3187,\n",
              "          -1.3058, -0.4890],\n",
              "         [-0.1844,  0.3723, -0.7960, -0.2162,  0.2121,  0.7338,  0.8952, -0.2755,\n",
              "          -0.4961,  0.1444],\n",
              "         [-0.0799,  0.4215, -0.1679,  0.7412, -0.0078,  0.1213, -0.3360,  0.0507,\n",
              "          -0.1702,  0.3801]]),\n",
              " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0431, 0.9569, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0061, 0.0185, 0.9754, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0413, 0.1330, 0.0716, 0.7540, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0031, 0.0156, 0.0130, 0.1025, 0.8659, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0877, 0.0397, 0.0837, 0.0542, 0.1371, 0.5977, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0029, 0.0086, 0.1068, 0.0264, 0.0055, 0.0042, 0.8456, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0232, 0.0318, 0.0813, 0.0541, 0.1619, 0.0246, 0.0995, 0.5236, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0778, 0.1855, 0.0411, 0.1218, 0.0634, 0.0246, 0.1449, 0.0867, 0.2543,\n",
              "          0.0000],\n",
              "         [0.0555, 0.0458, 0.1253, 0.0351, 0.0518, 0.2582, 0.0559, 0.0488, 0.0473,\n",
              "          0.2764]]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO: Why scaled?\n",
        "\n",
        "TL;DR softmax can get out of hand with large values"
      ],
      "metadata": {
        "id": "Y-c_uyAVUDzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "small_values = torch.tensor([1, 2, 3], dtype=torch.float32) # need dtype otherwise error\n",
        "big_values = small_values * 10\n",
        "huge_values = big_values * 10\n",
        "\n",
        "small_softmax = F.softmax(small_values, dim=0)\n",
        "big_softmax = F.softmax(big_values, dim=0)\n",
        "huge_softmax = F.softmax(huge_values, dim=0)\n",
        "\n",
        "print(f\"Small values: {small_values}\\nSmall softmax: {small_softmax}\\n\")\n",
        "print(f\"Big values: {big_values}\\nBig softmax: {big_softmax}\\n\")\n",
        "print(f\"Huge values: {huge_values}\\nHuge softmax: {huge_softmax}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9ZRWyJTUJUx",
        "outputId": "b4ed2782-c367-4edd-ae08-c75d80fa5106"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Small values: tensor([1., 2., 3.])\n",
            "Small softmax: tensor([0.0900, 0.2447, 0.6652])\n",
            "\n",
            "Big values: tensor([10., 20., 30.])\n",
            "Big softmax: tensor([2.0611e-09, 4.5398e-05, 9.9995e-01])\n",
            "\n",
            "Huge values: tensor([100., 200., 300.])\n",
            "Huge softmax: tensor([0.0000e+00, 3.7835e-44, 1.0000e+00])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO: Why dot-product?\n",
        "\n",
        "TL;DR dot product measures how closely two vectors are related\n",
        "\n",
        "* big values = close\n",
        "* negative values = far away\n",
        "* zero value = same direction? (TK - fix this)\n",
        "\n",
        "See:\n",
        "* 3blue1brown on dot product - https://www.youtube.com/watch?v=LyGKycYT2v0"
      ],
      "metadata": {
        "id": "lQV-oF1SUm8u"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hw3orswBU-GF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO: Replicate PyTorch's `scaled_dot_product_attention`\n",
        "\n",
        "(minus all the fancy optimizations, the library can do those for us)\n",
        "\n",
        "See: https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html\n",
        "\n",
        "Also see: https://github.com/facebookresearch/xformers/blob/main/xformers/components/attention/core.py#L297"
      ],
      "metadata": {
        "id": "Mi9DKRGiOQJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally use the context manager to ensure one of the fused kerenels is run\n",
        "torch.manual_seed(42)\n",
        "\n",
        "query = torch.rand(32, 8, 128, 64) # [batch_size, num_heads, sequence_length, embedding_dim]\n",
        "key = torch.rand(32, 8, 128, 64)\n",
        "value = torch.rand(32, 8, 128, 64)\n"
      ],
      "metadata": {
        "id": "_JdMr4Jbshcu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_pytorch = F.scaled_dot_product_attention(query, key, value)\n",
        "print(output_pytorch.shape)\n",
        "print(output_pytorch[0, 0, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDOCXshXQPxA",
        "outputId": "e5de2920-909c-4908-db52-53ffa5a4c145"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 8, 128, 64])\n",
            "tensor([0.5430, 0.5479, 0.5143, 0.4744, 0.5149, 0.4867, 0.5063, 0.5088, 0.4863,\n",
            "        0.4620, 0.4989, 0.5488, 0.4746, 0.4955, 0.5334, 0.4886, 0.5158, 0.5267,\n",
            "        0.5183, 0.5251, 0.4939, 0.5092, 0.5408, 0.4267, 0.4645, 0.5221, 0.5587,\n",
            "        0.4917, 0.5142, 0.4762, 0.4839, 0.4837, 0.4937, 0.4671, 0.4898, 0.5195,\n",
            "        0.4942, 0.4938, 0.4783, 0.4796, 0.5454, 0.4686, 0.5112, 0.5717, 0.5081,\n",
            "        0.4588, 0.5151, 0.4970, 0.4649, 0.5143, 0.5019, 0.5053, 0.4928, 0.5278,\n",
            "        0.5332, 0.5121, 0.4882, 0.4992, 0.5197, 0.4865, 0.5028, 0.4908, 0.4975,\n",
            "        0.4808])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def attention(query, key, value):\n",
        "  d_k = torch.tensor(query.shape[-1]) # torch.sqrt needs a tensor\n",
        "  print(torch.matmul(query, key.mT).shape)\n",
        "  print(key.mT.shape)\n",
        "  print(key.transpose(-2, -1).shape)\n",
        "\n",
        "  # tensor.mT is equivalent to tensor.transpose(-2, -1), see: https://pytorch.org/docs/stable/tensors.html#torch.Tensor.mT\n",
        "  # -> last two dimensions reversed\n",
        "  q_k = F.softmax(torch.matmul(query, key.mT)/torch.sqrt(d_k), dim=-1)\n",
        "\n",
        "  print(d_k)\n",
        "\n",
        "  print(d_k.shape, q_k.shape, value.shape)\n",
        "  print(q_k.shape, value.mT.shape)\n",
        "\n",
        "  return torch.matmul(q_k, value)\n",
        "\n",
        "output_custom = attention(query, key, value)\n",
        "print(output_pytorch.shape)\n",
        "print(output_pytorch[0, 0, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4j-VvKEpZVI",
        "outputId": "994b844c-84b5-4da8-a12f-17b08f0444bb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 8, 128, 128])\n",
            "torch.Size([32, 8, 64, 128])\n",
            "torch.Size([32, 8, 64, 128])\n",
            "tensor(64)\n",
            "torch.Size([]) torch.Size([32, 8, 128, 128]) torch.Size([32, 8, 128, 64])\n",
            "torch.Size([32, 8, 128, 128]) torch.Size([32, 8, 64, 128])\n",
            "torch.Size([32, 8, 128, 64])\n",
            "tensor([0.5430, 0.5479, 0.5143, 0.4744, 0.5149, 0.4867, 0.5063, 0.5088, 0.4863,\n",
            "        0.4620, 0.4989, 0.5488, 0.4746, 0.4955, 0.5334, 0.4886, 0.5158, 0.5267,\n",
            "        0.5183, 0.5251, 0.4939, 0.5092, 0.5408, 0.4267, 0.4645, 0.5221, 0.5587,\n",
            "        0.4917, 0.5142, 0.4762, 0.4839, 0.4837, 0.4937, 0.4671, 0.4898, 0.5195,\n",
            "        0.4942, 0.4938, 0.4783, 0.4796, 0.5454, 0.4686, 0.5112, 0.5717, 0.5081,\n",
            "        0.4588, 0.5151, 0.4970, 0.4649, 0.5143, 0.5019, 0.5053, 0.4928, 0.5278,\n",
            "        0.5332, 0.5121, 0.4882, 0.4992, 0.5197, 0.4865, 0.5028, 0.4908, 0.4975,\n",
            "        0.4808])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assert all of the output values are close\n",
        "assert torch.all(output_custom.isclose(output_pytorch))"
      ],
      "metadata": {
        "id": "axD45MIHpO3y"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What about einops?\n",
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZrCXRCQucfh",
        "outputId": "08146330-093e-4e07-d5c8-b364437d11f3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from einops import rearrange, reduce, repeat\n",
        "\n",
        "print(f\"Key shape: {key.shape} [batch, num_heads, input_sequence, embedding_dim]\")\n",
        "\n",
        "### The following all do the same ###\n",
        "\n",
        "# Rearrange the shape for our use case\n",
        "key_rearranged = rearrange(key, 'batch heads input embed -> batch heads embed input')\n",
        "\n",
        "# Key tranposed\n",
        "key_transposed = key.transpose(-2, -1)\n",
        "\n",
        "# Key mT (note: use .mT rather than .T on tensors with more than two dimensions)\n",
        "key_mt = key.mT\n",
        "\n",
        "print(key_rearranged.shape, key_transposed.shape, key_mt.shape)\n",
        "assert key_rearranged.shape == key_transposed.shape == key_mt.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWU9f--huvnB",
        "outputId": "b7aa6537-d8c9-42a9-c03d-09203f1a063d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key shape: torch.Size([32, 8, 128, 64]) [batch, num_heads, input_sequence, embedding_dim]\n",
            "torch.Size([32, 8, 64, 128]) torch.Size([32, 8, 64, 128]) torch.Size([32, 8, 64, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO: Why multi-head attention?\n",
        "\n",
        "TL;DR more opportunities to learn (e.g. 8x64 scaled dot-product attention = better than 1*512)\n",
        "\n",
        "TK:\n",
        "- One big matrix multiplication better than lots of small ones\n",
        "- Just perform a `nn.Linear()` then break it up"
      ],
      "metadata": {
        "id": "81KIT2MtYKyH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "InUnaU5hYY4i"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}