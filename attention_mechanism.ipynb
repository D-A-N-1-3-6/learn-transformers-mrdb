{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbourke/learn-transformers/blob/main/attention_mechanism.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usdE3sRsGnj_"
      },
      "source": [
        "# [WIP] Attention mechanism\n",
        "\n",
        "**Focus:** Build intuition to build up to replicating the original Transformer paper.\n",
        "\n",
        "### This notebook\n",
        "\n",
        "* Recreate self-attention as per Transformer paper\n",
        "* Recreate multi-head attention as per Transformer paper\n",
        "\n",
        "### Later\n",
        "* Recreate Transformer model architecture\n",
        "* Train on a simple example\n",
        "\n",
        "Sources:\n",
        "\n",
        "* Transformer paper: https://arxiv.org/abs/1706.03762\n",
        "* The annotated transformer: http://nlp.seas.harvard.edu/2018/04/01/attention.html\n",
        "* https://lilianweng.github.io/posts/2018-06-24-attention/#self-attention\n",
        "* https://jaykmody.com/blog/attention-intuition/\n",
        "* Compact transformers - https://medium.com/pytorch/training-compact-transformers-from-scratch-in-30-minutes-with-pytorch-ff5c21668ed5\n",
        "* Implemented MHA - https://nn.labml.ai/transformers/mha.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5lKkczcnUaI"
      },
      "source": [
        "## What we're going to do\n",
        "\n",
        "Simple goals:\n",
        "\n",
        "Replicate the following functions/modules as fast as possible:\n",
        "* PyTorch's `scaled_dot_product_attention` - https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html\n",
        "  * Explain the intuition of the attention mechanism\n",
        "* PyTorch's MultiHeadAttention - https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html\n",
        "  * Both of these are the same equations used in the Transformer paper\n",
        "* Do with and without masking\n",
        "* Use these to build on the next chatper: replicating the Transformer architecture\n",
        "  * Focus on what the inputs and outputs should be (e.g. text/vision/audio, in essence, seq2seq)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6-XaYYv9GcKP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvO_nyA2O6tZ"
      },
      "source": [
        "## Simple scaled-dot-product-attention (no mask)\n",
        "\n",
        "Attention formula = `softmax((Q, K.T)/torch.sqrt(d_k))V`\n",
        "\n",
        "$$\n",
        "\\operatorname{Attention}(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{\\mathrm{T}}}{\\sqrt{d_k}}\\right) V\n",
        "$$\n",
        "\n",
        "TK:\n",
        "- Explain what each of these values are\n",
        "\n",
        "TK:\n",
        "- Can I replicate this in Google Sheets?... yes I can... kind of (except for softmax, etc)\n",
        "- Turn this function into the same format as the transformer paper (e.g. figure 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nMVXnybZGhun"
      },
      "outputs": [],
      "source": [
        "def attention(query, key, value):\n",
        "\n",
        "  # Create the scale factor (sqrt(d_k))\n",
        "  d_k = torch.sqrt(torch.tensor(query.shape[-1])) # torch.sqrt needs a tensor\n",
        "\n",
        "  q_k = torch.matmul(query, key.mT) # .mT = matrix Transpose (transposes the last two dimensions)\n",
        "  q_k_softmax_scale = F.softmax(q_k/torch.sqrt(d_k), dim=-1)\n",
        "  q_k_softmax_scale_v = torch.matmul(q_k, value)\n",
        "  return q_k_softmax_scale_v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWgiQ8HWHjcK",
        "outputId": "0bbed3de-97f4-4c79-8572-eaf1f81fdcae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.7361, -0.3428,  0.4193],\n",
              "        [ 2.7884, -2.2552,  0.2486],\n",
              "        [12.6584, -4.6864,  2.5056]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "x = torch.randn(3, 3)\n",
        "\n",
        "output_custom = attention(query=x, key=x, value=x)\n",
        "output_custom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESpNb90liTrw",
        "outputId": "a90c0651-fc06-4b4f-dbd6-50c8cf2f317c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.1175, -0.5276,  0.2233],\n",
              "        [ 1.0066, -0.7048,  0.1397],\n",
              "        [ 1.9621, -0.6285,  0.4030]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Does this equal PyTorch's scaled_dot_product_attention?\n",
        "output_pytorch = F.scaled_dot_product_attention(query=x,\n",
        "                                                key=x,\n",
        "                                                value=x)\n",
        "output_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRLh4GQ9ihdk",
        "outputId": "de685fec-fda2-4efc-a4ef-72dfcedf41c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(False)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Should output true\n",
        "torch.all(output_pytorch.isclose(output_custom))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kxahii5xJRv"
      },
      "source": [
        "## TODO: What is a query, key and value?\n",
        "\n",
        "* What if I told you you already know about the attention mechanism?... and your local cafe owner knows it very well\n",
        "\n",
        "* Give an example of different values input and output into our attention mechansim\n",
        "\n",
        "TK - Can I do sales of different products? Does this relate?\n",
        "\n",
        "E.g.\n",
        "* query = sales on monday\n",
        "* key = product\n",
        "* value = amount?\n",
        "\n",
        "Does this work??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VbBzoBOxLj_",
        "outputId": "aa69d682-e4c2-453d-b0ef-d1f57171eeef"
      },
      "outputs": [],
      "source": [
        "# TODO: finalize this and upload it to GitHub (if it works)\n",
        "#!wget \n",
        "url = \"https://www.dropbox.com/s/8heqlnrpkf7tlbq/cafe_sales_data_csv.xlsx\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "p-wiDpW9xgVo",
        "outputId": "13f85468-70a9-4570-ff0d-9e102f3fa570"
      },
      "outputs": [
        {
          "ename": "URLError",
          "evalue": "<urlopen error [Errno 11002] getaddrinfo failed>",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\abyss\\workenv\\envs\\torchenv\\Lib\\urllib\\request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1348\u001b[0m     h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1349\u001b[0m               encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\abyss\\workenv\\envs\\torchenv\\Lib\\http\\client.py:1303\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1303\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(method, url, body, headers, encode_chunked)\n",
            "File \u001b[1;32mc:\\Users\\abyss\\workenv\\envs\\torchenv\\Lib\\http\\client.py:1349\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders(body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
            "File \u001b[1;32mc:\\Users\\abyss\\workenv\\envs\\torchenv\\Lib\\http\\client.py:1298\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
            "File \u001b[1;32mc:\\Users\\abyss\\workenv\\envs\\torchenv\\Lib\\http\\client.py:1058\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1058\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1061\u001b[0m \n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\abyss\\workenv\\envs\\torchenv\\Lib\\http\\client.py:996\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 996\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m    997\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\abyss\\workenv\\envs\\torchenv\\Lib\\http\\client.py:1468\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1466\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnect to a host on a given (SSL) port.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1468\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n",
            "File \u001b[1;32mc:\\Users\\abyss\\workenv\\envs\\torchenv\\Lib\\http\\client.py:962\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    961\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[1;32m--> 962\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection(\n\u001b[0;32m    963\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_address)\n\u001b[0;32m    964\u001b[0m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\abyss\\workenv\\envs\\torchenv\\Lib\\socket.py:827\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[0;32m    826\u001b[0m exceptions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 827\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m getaddrinfo(host, port, \u001b[38;5;241m0\u001b[39m, SOCK_STREAM):\n\u001b[0;32m    828\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
            "File \u001b[1;32mc:\\Users\\abyss\\workenv\\envs\\torchenv\\Lib\\socket.py:962\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    961\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 962\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m _socket\u001b[38;5;241m.\u001b[39mgetaddrinfo(host, port, family, \u001b[38;5;28mtype\u001b[39m, proto, flags):\n\u001b[0;32m    963\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
            "\u001b[1;31mgaierror\u001b[0m: [Errno 11002] getaddrinfo failed",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(url) \u001b[38;5;66;03m# TODO: read_excel with _csv in the filename is confusing...\u001b[39;00m\n\u001b[0;32m      3\u001b[0m df\n",
            "File \u001b[1;32mc:\\Users\\abyss\\workenv\\envs\\torchenv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(\n\u001b[0;32m    496\u001b[0m         io,\n\u001b[0;32m    497\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    498\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    499\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\abyss\\workenv\\envs\\torchenv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m inspect_excel_format(\n\u001b[0;32m   1551\u001b[0m         content_or_path\u001b[38;5;241m=\u001b[39mpath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[0;32m   1552\u001b[0m     )\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\abyss\\workenv\\envs\\torchenv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m   1403\u001b[0m     content_or_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1404\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\abyss\\workenv\\envs\\torchenv\\Lib\\site-packages\\pandas\\io\\common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[1;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m _get_filepath_or_buffer(\n\u001b[0;32m    729\u001b[0m     path_or_buf,\n\u001b[0;32m    730\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    731\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    732\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    733\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    734\u001b[0m )\n\u001b[0;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
            "File \u001b[1;32mc:\\Users\\abyss\\workenv\\envs\\torchenv\\Lib\\site-packages\\pandas\\io\\common.py:384\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[0;32m    383\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[1;32m--> 384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urlopen(req_info) \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[0;32m    385\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    387\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\abyss\\workenv\\envs\\torchenv\\Lib\\site-packages\\pandas\\io\\common.py:289\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\abyss\\workenv\\envs\\torchenv\\Lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
            "File \u001b[1;32mc:\\Users\\abyss\\workenv\\envs\\torchenv\\Lib\\urllib\\request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(req, data)\n\u001b[0;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\abyss\\workenv\\envs\\torchenv\\Lib\\urllib\\request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_open, protocol, protocol \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    537\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_open\u001b[39m\u001b[38;5;124m'\u001b[39m, req)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[1;32mc:\\Users\\abyss\\workenv\\envs\\torchenv\\Lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[1;32mc:\\Users\\abyss\\workenv\\envs\\torchenv\\Lib\\urllib\\request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_open(http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mHTTPSConnection, req,\n\u001b[0;32m   1392\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context, check_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_hostname)\n",
            "File \u001b[1;32mc:\\Users\\abyss\\workenv\\envs\\torchenv\\Lib\\urllib\\request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1349\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
            "\u001b[1;31mURLError\u001b[0m: <urlopen error [Errno 11002] getaddrinfo failed>"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel(url) # TODO: read_excel with _csv in the filename is confusing...\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o-GJZj-zWsg",
        "outputId": "fddfad36-8d31-4704-8ae1-48fc784de497"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 5.,  8., 15.,  4.,  9., 12.,  8.])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create price vector\n",
        "price_dict = {\n",
        "    \"coffee\": 5,\n",
        "    \"bread\": 8,\n",
        "    \"bacon\": 15,\n",
        "    \"milk\": 4,\n",
        "    \"bagel\": 9,\n",
        "    \"sandwich\": 12,\n",
        "    \"croissant\": 8\n",
        "}\n",
        "price_vector = torch.tensor(list(price_dict.values()), dtype=torch.float32)\n",
        "price_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLZgRl5Dz51v",
        "outputId": "2e319b55-4edf-4d88-d1f8-e2ab631f3a59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  0.,  50.,  55.,  68.,  91., 107.,  84.],\n",
              "        [  0.,  20.,  22.,  25.,  12.,  40.,  49.],\n",
              "        [  0.,  10.,  15.,  20.,  10.,  65.,  39.],\n",
              "        [  0.,  15.,  15.,  18.,  16.,  51.,  45.],\n",
              "        [  0.,  21.,   8.,  20.,  60.,  56.,  44.],\n",
              "        [  0.,   9.,   8.,  50.,  18.,  62.,  50.],\n",
              "        [  0.,  11.,   4.,   3.,   7.,  49.,  55.]])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create sales matrix\n",
        "sales_matrix = torch.tensor(df.drop(\"Unnamed: 0\", axis=1).values, dtype=torch.float32)\n",
        "sales_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S_HxbAn0dQ9",
        "outputId": "3378da72-ae13-47b0-e12f-3ac99976099d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sales: torch.Size([7, 7]) (seven products, seven days of week)\n",
            "Prices: torch.Size([7]) (seven products)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Sales: {sales_matrix.shape} (seven products, seven days of week)\")\n",
        "print(f\"Prices: {price_vector.shape} (seven products)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5FLeA5Z0HIa",
        "outputId": "33d58041-ad83-4bc7-8ff1-33347abede98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([   0., 1005.,  936., 1716., 1577., 3674., 3013.])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the sales per day\n",
        "price_vector.matmul(sales_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZtS_qvk8xDp",
        "outputId": "b1795b29-51c3-4650-da12-8a4627d31869"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 5.],\n",
              "        [ 8.],\n",
              "        [15.],\n",
              "        [ 4.],\n",
              "        [ 9.],\n",
              "        [12.],\n",
              "        [ 8.]])"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "price_vector.unsqueeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx-vuk0P8zr2",
        "outputId": "a3b098c4-968f-4c3b-8e8b-ffdb14fac107"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 5.,  8., 15.,  4.,  9., 12.,  8.])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "price_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvmvVBmC809o",
        "outputId": "488fbb17-91e1-4717-a2ae-436c24f48140"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[   0.,  400.,  825.,  272.,  819., 1284.,  672.],\n",
              "        [   0.,  160.,  330.,  100.,  108.,  480.,  392.],\n",
              "        [   0.,   80.,  225.,   80.,   90.,  780.,  312.],\n",
              "        [   0.,  120.,  225.,   72.,  144.,  612.,  360.],\n",
              "        [   0.,  168.,  120.,   80.,  540.,  672.,  352.],\n",
              "        [   0.,   72.,  120.,  200.,  162.,  744.,  400.],\n",
              "        [   0.,   88.,   60.,   12.,   63.,  588.,  440.]])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# WRONG: Sales per item per day\n",
        "price_vector * sales_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBhJxz2I8k6v",
        "outputId": "dc1b296d-fd9d-4f33-c6e6-6825990d1423"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  0., 250., 275., 340., 455., 535., 420.],\n",
              "        [  0., 160., 176., 200.,  96., 320., 392.],\n",
              "        [  0., 150., 225., 300., 150., 975., 585.],\n",
              "        [  0.,  60.,  60.,  72.,  64., 204., 180.],\n",
              "        [  0., 189.,  72., 180., 540., 504., 396.],\n",
              "        [  0., 108.,  96., 600., 216., 744., 600.],\n",
              "        [  0.,  88.,  32.,  24.,  56., 392., 440.]])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# CORRECT: Manipulate price vector before multiplying to sales matrix\n",
        "price_vector.unsqueeze(1) * sales_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVAyGUxf1Gjh",
        "outputId": "cedd12b5-a4f7-47e3-9fcb-c3cdc619a39d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2275., 1344., 2385.,  640., 1881., 2364., 1032.])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TK note:\n",
        "# matmul = sum over dim=0 -> item sales per day\n",
        "# manual setup = sum over dim=1 -> item sales per week\n",
        "total_item_sales_per_week = torch.sum(price_vector.unsqueeze(1) * sales_matrix, dim=1)\n",
        "total_item_sales_per_week"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycUpMtzo3rM2",
        "outputId": "1711d553-b1e6-44d2-e63e-7bc0e2c61f9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([   0., 1005.,  936., 1716., 1577., 3674., 3013.])"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_sales_per_day = torch.sum(price_vector.unsqueeze(1) * sales_matrix, dim=0)\n",
        "total_sales_per_day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkDxDRjy_ZXx"
      },
      "outputs": [],
      "source": [
        "# TODO: try einsum? or einops?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YL5oCz54_Usa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA8p_lGV6H6t"
      },
      "source": [
        "TK - try create an example for attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SriEVG8E7B0I",
        "outputId": "725be710-b916-4393-cb44-8766875f7c89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 0., 1., 0., 0., 0., 0.])"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a query (\"What are the sales on Wednesday?\")\n",
        "sales_on_wednesday_vector = torch.zeros(7) # days of week\n",
        "sales_on_wednesday_vector[2] = 1\n",
        "sales_on_wednesday_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO50157P7Bu2",
        "outputId": "b4185fb0-1a4e-4840-8567-6be31cc5579e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([55., 22., 15., 15.,  8.,  8.,  4.])"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compare the sales matrix (key) to the query (Q * K.T)\n",
        "wednesday_sales = sales_on_wednesday_vector.matmul(sales_matrix.T)\n",
        "wednesday_sales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLGf-DMcByHS"
      },
      "source": [
        "Why scale?\n",
        "\n",
        "Watch this... softmax blows it out of the water..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1pLOP90Bp0T",
        "outputId": "1233565b-9f74-4989-ef2e-0c008022f05a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1.0000e+00, 4.6589e-15, 4.2484e-18, 4.2484e-18, 3.8740e-21, 3.8740e-21,\n",
              "        7.0955e-23])"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "F.softmax(wednesday_sales, dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEgKwEOsB2MN"
      },
      "source": [
        "Now scale..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taUwRq-BB-ew",
        "outputId": "20a4fb7d-edc3-4414-94b4-c930051e004d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([7])"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wednesday_sales.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIYjdkbcB19e",
        "outputId": "b57eac29-517b-40ad-f16d-ad8f6b9b8416"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1.0000e+00, 3.8293e-06, 2.7170e-07, 2.7170e-07, 1.9277e-08, 1.9277e-08,\n",
              "        4.2507e-09])"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "F.softmax(wednesday_sales / torch.sqrt(torch.tensor(wednesday_sales.shape[0])), dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTsvFYZKCVGP"
      },
      "source": [
        "Still blown out of the water but better... (could normalize these values first)\n",
        "\n",
        "e.g.\n",
        "\n",
        "```python\n",
        "norm_tensor = (x - torch.min(x))/(torch.max(x) - torch.min(x))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu04zf4YCM9t",
        "outputId": "eafefa4e-5755-4a63-f299-3e43d06b7a60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(5.0000)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "F.softmax(wednesday_sales / torch.sqrt(torch.tensor(wednesday_sales.shape[0])), dim=0) @ price_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuEgA-T46ed1",
        "outputId": "b08c6bce-f2c0-483f-bb99-29f49158cac2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(936.)"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Total sales on Wednesday\n",
        "attention_to_pay_on_wednesdays = wednesday_sales @ price_vector # price_vector = value\n",
        "attention_to_pay_on_wednesdays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-Ca0y5UsAEi"
      },
      "source": [
        "### TODO: Try normalizing values\n",
        "\n",
        "See:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuowdQTzDiAN"
      },
      "outputs": [],
      "source": [
        "# NEXT:\n",
        "# Try normalizing the tensor values and see how they change/improve stability\n",
        "# Softmax on values with large differences = blows larger values out of the water (e.g. 1.0 vs 1e-10... basically nothing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_5LMpFwsjIK",
        "outputId": "3e70f79a-6f3e-4d77-c3a0-c6af22e981b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        ],\n",
              "       [0.        , 0.26829268, 0.35294118, 0.33846154, 0.05952381,\n",
              "        0.        , 0.22222222],\n",
              "       [0.        , 0.02439024, 0.21568627, 0.26153846, 0.03571429,\n",
              "        0.37313433, 0.        ],\n",
              "       [0.        , 0.14634146, 0.21568627, 0.23076923, 0.10714286,\n",
              "        0.1641791 , 0.13333333],\n",
              "       [0.        , 0.29268293, 0.07843137, 0.26153846, 0.63095238,\n",
              "        0.23880597, 0.11111111],\n",
              "       [0.        , 0.        , 0.07843137, 0.72307692, 0.13095238,\n",
              "        0.32835821, 0.24444444],\n",
              "       [0.        , 0.04878049, 0.        , 0.        , 0.        ,\n",
              "        0.13432836, 0.35555556]])"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "min_max = MinMaxScaler()\n",
        "sales_matrix_normalized = min_max.fit(sales_matrix).transform(sales_matrix)\n",
        "sales_matrix_normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2trYpZ2sC5I"
      },
      "outputs": [],
      "source": [
        "def min_max_normalize_tensor(x):\n",
        "  \"\"\"\n",
        "  See: https://en.wikipedia.org/wiki/Feature_scaling#Rescaling_(min-max_normalization)\n",
        "  \"\"\"\n",
        "\n",
        "  return (x - torch.min(x)) / (torch.max(x) - torch.min(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxx7LY51tHyK",
        "outputId": "1ea73450-e9c7-4a4c-dd73-9da46c925a25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 5.,  8., 15.,  4.,  9., 12.,  8.])"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "price_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdyBFi9LsODb",
        "outputId": "107adca3-90f1-4a1a-b57d-7a00b0e2ebfd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.0000, 0.4673, 0.5140, 0.6355, 0.8505, 1.0000, 0.7850],\n",
              "         [0.0000, 0.1869, 0.2056, 0.2336, 0.1121, 0.3738, 0.4579],\n",
              "         [0.0000, 0.0935, 0.1402, 0.1869, 0.0935, 0.6075, 0.3645],\n",
              "         [0.0000, 0.1402, 0.1402, 0.1682, 0.1495, 0.4766, 0.4206],\n",
              "         [0.0000, 0.1963, 0.0748, 0.1869, 0.5607, 0.5234, 0.4112],\n",
              "         [0.0000, 0.0841, 0.0748, 0.4673, 0.1682, 0.5794, 0.4673],\n",
              "         [0.0000, 0.1028, 0.0374, 0.0280, 0.0654, 0.4579, 0.5140]]),\n",
              " tensor([0.0909, 0.3636, 1.0000, 0.0000, 0.4545, 0.7273, 0.3636]))"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sales_matrix_normalized = min_max_normalize_tensor(sales_matrix)\n",
        "price_vector_normalized = min_max_normalize_tensor(price_vector)\n",
        "sales_matrix_normalized, price_vector_normalized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aWRusXYvd57"
      },
      "source": [
        "### TODO: Try standardizing\n",
        "\n",
        "See: https://en.wikipedia.org/wiki/Feature_scaling#Standardization_(Z-score_Normalization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTRH-apNwvjA",
        "outputId": "50d5f064-168e-45c8-87f8-6da92e5bec85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1.1125, 0.6311, 0.3288])"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.std(x, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZRKiDpAtc-x"
      },
      "outputs": [],
      "source": [
        "def standardize_tensor(x):\n",
        "  \"\"\"\n",
        "  See: https://en.wikipedia.org/wiki/Feature_scaling#Standardization_(Z-score_Normalization)\n",
        "  \"\"\"\n",
        "  return (x - torch.mean(x)) / torch.std(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTez0hPFtu8W",
        "outputId": "bb908786-8c6b-4f6f-f308-6d80effd56d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.9730, -0.1871,  1.6467, -1.2350,  0.0748,  0.8608, -0.1871])"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sales_matrix_standardized = standardize_tensor(sales_matrix)\n",
        "price_vector_standardized = standardize_tensor(price_vector)\n",
        "price_vector_standardized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mITQQ6hxvlIa",
        "outputId": "dbf336c6-f3c0-4a74-8014-308bf644c6e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 5.,  8., 15.,  4.,  9., 12.,  8.])"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "price_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_oOeaPmwA6_",
        "outputId": "70e1f4a5-10c9-4328-867e-5f8dc9bee717"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 0., 1., 0., 0., 0., 0.])"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a query (\"What are the sales on Wednesday?\")\n",
        "sales_on_wednesday_vector = torch.zeros(7) # days of week\n",
        "sales_on_wednesday_vector[2] = 1\n",
        "sales_on_wednesday_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4E_ws9XxoDV",
        "outputId": "80909fe4-cbac-4801-c8d4-0ae01dc06f70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-1.1194,  0.7374,  0.9231,  1.4059,  2.2600,  2.8542,  2.0000],\n",
              "        [-1.1194, -0.3767, -0.3024, -0.1910, -0.6738,  0.3661,  0.7003],\n",
              "        [-1.1194, -0.7480, -0.5623, -0.3767, -0.7480,  1.2945,  0.3289],\n",
              "        [-1.1194, -0.5623, -0.5623, -0.4509, -0.5252,  0.7745,  0.5517],\n",
              "        [-1.1194, -0.3395, -0.8223, -0.3767,  1.1088,  0.9602,  0.5146],\n",
              "        [-1.1194, -0.7852, -0.8223,  0.7374, -0.4509,  1.1830,  0.7374],\n",
              "        [-1.1194, -0.7109, -0.9708, -1.0080, -0.8594,  0.7003,  0.9231]])"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sales_matrix_standardized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKPYq8Ct1u7v",
        "outputId": "1cae4ad2-d161-4365-cfd1-77e728024aaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.0365])"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "F.softmax(sales_on_wednesday_vector.unsqueeze(0).matmul(sales_matrix_standardized.T)/7, dim=1) @ price_vector_standardized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl1v3T_T2LhR",
        "outputId": "b6ee919a-5e8b-4da8-bb46-77ff5926fdfb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([5.0707])"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "F.softmax(sales_on_wednesday_vector.unsqueeze(0).matmul(sales_matrix.T)/7, dim=1) @ price_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_jXH4cR2VFu",
        "outputId": "ed3d2227-8c1c-496a-eb48-a2b79a70f4f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 0., 0., 0., 0., 0., 0.])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([8.7143])"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sales_on_monday = torch.zeros(7)\n",
        "sales_on_monday[0] = 1\n",
        "print(sales_on_monday)\n",
        "F.softmax(sales_on_monday.unsqueeze(0).matmul(sales_matrix.T)/7, dim=1) @ price_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvka9Z5y3kej"
      },
      "outputs": [],
      "source": [
        "# Non-standardize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugNTSb3y3R_A",
        "outputId": "8ab98cbb-5333-4469-8e6f-00fb63d4a00f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0., 0., 0., 1., 0.])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([-0.0193])"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sales_on_monday = torch.zeros(7)\n",
        "sales_on_monday[5] = 1\n",
        "print(sales_on_monday)\n",
        "F.softmax(sales_on_monday.unsqueeze(0).matmul(sales_matrix_standardized.T)/7, dim=1) @ price_vector_standardized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHIuE8LG3-gB",
        "outputId": "1d645388-2c61-485a-8b4a-39b3e388917c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'Monday',\n",
              " 1: 'Tuesday',\n",
              " 2: 'Wednesday',\n",
              " 3: 'Thursday',\n",
              " 4: 'Friday',\n",
              " 5: 'Saturday',\n",
              " 6: 'Sunday'}"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "day_names = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
        "day_values = range(0, 7)\n",
        "day_dict = dict(zip(day_values, day_names))\n",
        "day_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "lOffwA9T5KAl",
        "outputId": "c4f5d1b5-ce40-4c20-d343-9fabba920f13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Day name: Monday\n",
            "Day tensor: tensor([1., 0., 0., 0., 0., 0., 0.])\n",
            "7\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-b4ad1a2c8a36>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0md_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mday_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mattn_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mday_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msales_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mprice_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Attention score: {attn_score}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (7x1 and 7x7)"
          ]
        }
      ],
      "source": [
        "# Non-standardize\n",
        "for i in range(7):\n",
        "  day_tensor = torch.zeros(7)\n",
        "  day_tensor[i] = 1\n",
        "  day_name = day_dict[i]\n",
        "\n",
        "  print(f\"\\nDay name: {day_name}\")\n",
        "  print(f\"Day tensor: {day_tensor}\")\n",
        "  # day_tensor_standardize = standardize_tensor(day_tensor)\n",
        "  d_k = day_tensor.shape[-1]\n",
        "  print(d_k)\n",
        "  attn_score = F.softmax(day_tensor.unsqueeze(1).matmul(sales_matrix.T)/torch.sqrt(torch.tensor(7)), dim=1) @ price_vector\n",
        "  print(f\"Attention score: {attn_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_NZHBaP3yrT"
      },
      "outputs": [],
      "source": [
        "# Standardize\n",
        "# TODO: does this work for the triangle matrix?\n",
        "# e.g. triangle down the left to bottom right corner\n",
        "for i in range(7):\n",
        "  day_tensor = torch.zeros(7)\n",
        "  day_tensor[i] = 1\n",
        "  day_name = day_dict[i]\n",
        "\n",
        "  print(f\"\\nDay name: {day_name}\")\n",
        "  print(f\"Day tensor: {day_tensor}\")\n",
        "  day_tensor_standardize = standardize_tensor(day_tensor)\n",
        "  attn_score = F.softmax(day_tensor_standardize.unsqueeze(0).matmul(sales_matrix_standardized.T)/torch.sqrt(torch.tensor(7)), dim=1) @ price_vector_standardized\n",
        "  print(f\"Attention score: {attn_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trRr4ecr5wWM"
      },
      "outputs": [],
      "source": [
        "all_days = torch.eye(7)\n",
        "\n",
        "attention(query=all_days,\n",
        "          key=sales_matrix,\n",
        "          value=price_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkCmpcUU59Us"
      },
      "outputs": [],
      "source": [
        "all_days = torch.eye(7)\n",
        "all_days_standardized = standardize_tensor(all_days)\n",
        "\n",
        "attention(query=all_days_standardized,\n",
        "          key=sales_matrix_standardized,\n",
        "          value=price_vector_standardized.unsqueeze(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef98o0s87GsN"
      },
      "outputs": [],
      "source": [
        "F.scaled_dot_product_attention(query=all_days_standardized,\n",
        "                               key=sales_matrix_standardized,\n",
        "                               value=price_vector_standardized.unsqueeze(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWh0w0Rq6WDv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yw00WM556WAm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I66hYN8o3lVv"
      },
      "outputs": [],
      "source": [
        "standardize_tensor_day = standardize_tensor(sales_on_monday)\n",
        "standardize_tensor_day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67wQyMucxUab"
      },
      "outputs": [],
      "source": [
        "# Combine with the key (<q, k.T>)\n",
        "wednesday_sales = sales_on_wednesday_vector.matmul(sales_matrix_standardized.T)\n",
        "wednesday_sales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4eEMXfIx20s"
      },
      "outputs": [],
      "source": [
        "sales_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0BQ9phtxUX7"
      },
      "outputs": [],
      "source": [
        "# Softmax on the sales (not so blown out! ... once the values were standardized)\n",
        "wednesday_sales = F.softmax(wednesday_sales, dim=0)\n",
        "wednesday_sales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oov-red4ysd4"
      },
      "outputs": [],
      "source": [
        "# Scale on the sales\n",
        "wednesday_sales = wednesday_sales/torch.sqrt(torch.tensor(wednesday_sales.shape[0]))\n",
        "wednesday_sales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_rEK_5ExUVF"
      },
      "outputs": [],
      "source": [
        "# Multiply by the value to get the attention\n",
        "attention_to_pay_on_wednesdays = wednesday_sales @ price_vector_standardized\n",
        "attention_to_pay_on_wednesdays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjUzl-C0x6I-"
      },
      "outputs": [],
      "source": [
        "price_vector_standardized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OV9D0bVzLET"
      },
      "outputs": [],
      "source": [
        "each_day = torch.eye(7)\n",
        "each_day_standardized = standardize_tensor(each_day)\n",
        "each_day, each_day_standardized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kl-IsEFVzK5b"
      },
      "outputs": [],
      "source": [
        "# Attention to pay each day\n",
        "each_day = torch.ones((7))\n",
        "\n",
        "def attention(query, key, value):\n",
        "  d_k = torch.tensor(query.shape[-1]) # torch.sqrt needs a tensor\n",
        "  print(d_k)\n",
        "  q_k = F.softmax(torch.matmul(query, key.T)/torch.sqrt(d_k), dim=-1)\n",
        "  print(q_k.shape)\n",
        "  return torch.matmul(q_k, value)\n",
        "\n",
        "attention(query=each_day_standardized,\n",
        "          key=sales_matrix_standardized,\n",
        "          value=price_vector_standardized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pX_UFBsf5hOZ"
      },
      "outputs": [],
      "source": [
        "# Attention to pay each day\n",
        "monday = torch.zeros(7)\n",
        "monday[0] = 1\n",
        "monday_standardized = standardize_tensor(monday)\n",
        "print(monday)\n",
        "print(monday_standardized)\n",
        "\n",
        "def attention(query, key, value):\n",
        "  d_k = torch.tensor(query.shape[-1]) # torch.sqrt needs a tensor\n",
        "  print(d_k)\n",
        "  q_k = F.softmax(torch.matmul(query, key.T)/torch.sqrt(d_k), dim=-1)\n",
        "  print(q_k.shape)\n",
        "  return torch.matmul(q_k, value)\n",
        "\n",
        "attention(query=monday_standardized,\n",
        "          key=sales_matrix_standardized,\n",
        "          value=price_vector_standardized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpMubs4O5r0e"
      },
      "outputs": [],
      "source": [
        "# UPTOHERE\n",
        "# NEXT: clean up all of the above so it makes sense... in a bit of a mess now\n",
        "# Less but better..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kt5_dUGp5hG8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boXf5xSb1VJ2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Y5OVpaQ8qJ6"
      },
      "outputs": [],
      "source": [
        "# query = day of week\n",
        "# key = sales per day\n",
        "# value = prices of products\n",
        "# result/output = value of total products sold on target day (how much attention to pay to a certain day)\n",
        "\n",
        "# TK - if you wanted to get more information, you could increase the cafe sales to (52, 7) -> sales per day for 52 weeks in a year\n",
        "# -> or (5, 52, 7) (year, weeks, days) -> sales per day per week for 5 years\n",
        "\n",
        "# TODO:\n",
        "\n",
        "# How does this relate to attention?\n",
        "\n",
        "# At a large enough scale, you can do this for words in sentences.\n",
        "# For example, say we have 100 sentences.\n",
        "# Which words mean the most to which other words?\n",
        "# In a small sample like this, you might be able to design fixed values (like our coffee shop for different products).\n",
        "# But with a larger scale, you might have to design different values for different contexts.\n",
        "# The analogy being in a coffee shop in Australia, your pricing and products might be different to a coffee shop in Africa.\n",
        "# With a large enough corpus of words, having fixed values isn't going to work.\n",
        "# But the principle remains, how important is each other word to another word in a sentence?\n",
        "# What should you do?\n",
        "# Well, you'd never have time to assign a value for each word across a huge corpus.\n",
        "# So you can make the values for each word learnable.\n",
        "# Much like you might adjust your cafe prices and sales events given different days of the week.\n",
        "# The sales on Monday are very low (zero) because your cafe is closed on Monday.\n",
        "# Your customers don't assign much money (or attention) to your cafe on Monday's since they know it's closed.\n",
        "# Much like the attention score for the word \"cat\" might be very low in comparison to the word \"sodium metabisulfite\" because the two hardly ever occur in context of each other.\n",
        "\n",
        "# Why self-attention?\n",
        "\n",
        "# Applying the mechanism to itself over and over for different sequences enables the system to learn from the data itself.\n",
        "# As in, what words keep on showing up in the context of other words?\n",
        "# The dot product/matrix multiplication will amplify larger values.\n",
        "# In essence, given the query \"dog\" and the key of every word in the vocabulary, hopefully the model will learn to return \"cat\" as a likely value and \"sodium metabisulfite\" as a less likely value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mVfO_5m8qFn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xKawhtOcYfI"
      },
      "source": [
        "## TODO: Simple scaled-dot-product-attention (with mask)\n",
        "\n",
        "Next:\n",
        "- Read through GPT-from-scratch again\n",
        "- Read through Facebook's xformers\n",
        "- Read through Transformers from scratch blog post\n",
        "\n",
        "--\n",
        "\n",
        "* see: https://jaykmody.com/blog/gpt-from-scratch/#causal\n",
        "* And see: https://github.com/facebookresearch/xformers/blob/main/xformers/components/attention/attention_mask.py\n",
        "  * Default to causal mask: https://github.com/facebookresearch/xformers/blob/97daac83cece6d3d77bb09479777ad6e8ef7dfed/xformers/components/attention/attention_mask.py#LL74C16-L74C16 (`make_causal()`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-66nS-Rdp0ox"
      },
      "outputs": [],
      "source": [
        "# Make causal mask, see: https://jaykmody.com/blog/gpt-from-scratch/#causal\n",
        "additive_mask = torch.triu(\n",
        "    # torch.ones(x.shape[0], x.shape[0]) * float(\"inf\"),\n",
        "    torch.ones(x.shape[0], x.shape[0]) * -1e10, # can use -1e10 to prevent nans\n",
        "    diagonal=1\n",
        ")\n",
        "\n",
        "additive_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJcxus6qcYRE"
      },
      "outputs": [],
      "source": [
        "def attention_with_mask(query, key, value, mask=None):\n",
        "  d_k = torch.tensor(query.shape[-1]) # torch.sqrt needs a tensor\n",
        "  q_k = torch.matmul(query, key.T) / torch.sqrt(d_k)\n",
        "  print(q_k.shape)\n",
        "\n",
        "\n",
        "  print(f\"q_k: {q_k}\")\n",
        "\n",
        "  # Apply attention mask\n",
        "  if mask is not None:\n",
        "    q_k = q_k + mask\n",
        "\n",
        "  print(f\"q_k with mask: {q_k}\")\n",
        "\n",
        "  # Softmax\n",
        "  attn = F.softmax(q_k, dim=-1)\n",
        "\n",
        "  return torch.matmul(attn, value), attn\n",
        "\n",
        "attention_with_mask(query=x, key=x, value=x, mask=additive_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-c_uyAVUDzT"
      },
      "source": [
        "## TODO: Why scaled?\n",
        "\n",
        "TL;DR softmax can get out of hand with large values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9ZRWyJTUJUx"
      },
      "outputs": [],
      "source": [
        "small_values = torch.tensor([1, 2, 3], dtype=torch.float32) # need dtype otherwise error\n",
        "big_values = small_values * 10\n",
        "huge_values = big_values * 10\n",
        "\n",
        "small_softmax = F.softmax(small_values, dim=0)\n",
        "big_softmax = F.softmax(big_values, dim=0)\n",
        "huge_softmax = F.softmax(huge_values, dim=0)\n",
        "\n",
        "print(f\"Small values: {small_values}\\nSmall softmax: {small_softmax}\\n\")\n",
        "print(f\"Big values: {big_values}\\nBig softmax: {big_softmax}\\n\")\n",
        "print(f\"Huge values: {huge_values}\\nHuge softmax: {huge_softmax}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQV-oF1SUm8u"
      },
      "source": [
        "## TODO: Why dot-product?\n",
        "\n",
        "TL;DR dot product measures how closely two vectors are related\n",
        "\n",
        "* big values = close\n",
        "* negative values = far away\n",
        "* zero value = same direction? (TK - fix this)\n",
        "\n",
        "See:\n",
        "* 3blue1brown on dot product - https://www.youtube.com/watch?v=LyGKycYT2v0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hw3orswBU-GF"
      },
      "outputs": [],
      "source": [
        "vector_1 = torch.arange(0, 1, 0.1)\n",
        "vector_2 = torch.ones_like(vector_1) / 10\n",
        "vector_3 = vector_1 - 0.1\n",
        "vector_4 = -vector_1\n",
        "print(vector_2)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(vector_1, label=\"vector_1\")\n",
        "plt.plot(vector_2, label=\"vector_2\")\n",
        "plt.plot(vector_3, label=\"vector_3\")\n",
        "plt.plot(vector_4, label=\"vector_4\")\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btLpmYjjnzqQ"
      },
      "outputs": [],
      "source": [
        "cosine_sim = nn.CosineSimilarity(dim=0)\n",
        "cosine_sim(vector_1, vector_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wt1GW6VDm-Bx"
      },
      "outputs": [],
      "source": [
        "torch.dot(vector_1, vector_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUpB8NIcmksx"
      },
      "outputs": [],
      "source": [
        "torch.dot(vector_1, vector_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhCy5erUmnFR"
      },
      "outputs": [],
      "source": [
        "torch.dot(vector_1, vector_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJiwFLoKmuvp"
      },
      "outputs": [],
      "source": [
        "torch.dot(vector_2, vector_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OWoPXzgm4Q2"
      },
      "outputs": [],
      "source": [
        "torch.dot(vector_1, vector_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ok_hMVtpoVRy"
      },
      "outputs": [],
      "source": [
        "# Sales example (total sales on Wednesday)\n",
        "torch.dot(price_vector, sales_matrix[:, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMiVEvINo_3U"
      },
      "outputs": [],
      "source": [
        "# Same as taking the multiple and then summing them\n",
        "torch.sum(price_vector * df[\"Wednesday\"].values, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5j6vCJcoolV3"
      },
      "outputs": [],
      "source": [
        "# Compresses the information into a single number\n",
        "cosine_sim(price_vector, price_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqpIVmJjqF-g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.dot(price_vector, price_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi9DKRGiOQJw"
      },
      "source": [
        "## TODO: Replicate PyTorch's `scaled_dot_product_attention`\n",
        "\n",
        "(minus all the fancy optimizations, the library can do those for us)\n",
        "\n",
        "See: https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html\n",
        "\n",
        "Also see: https://github.com/facebookresearch/xformers/blob/main/xformers/components/attention/core.py#L297"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JdMr4Jbshcu"
      },
      "outputs": [],
      "source": [
        "# Optionally use the context manager to ensure one of the fused kerenels is run\n",
        "torch.manual_seed(42)\n",
        "\n",
        "query = torch.rand(32, 8, 128, 64) # [batch_size, num_heads, sequence_length, embedding_dim]\n",
        "key = torch.rand(32, 8, 128, 64)\n",
        "value = torch.rand(32, 8, 128, 64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDOCXshXQPxA",
        "outputId": "625d1bf1-d2c2-4809-9c73-5f451dfa2609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 8, 128, 64])\n",
            "tensor([0.5430, 0.5479, 0.5143, 0.4744, 0.5149, 0.4867, 0.5063, 0.5088, 0.4863,\n",
            "        0.4620, 0.4989, 0.5488, 0.4746, 0.4955, 0.5334, 0.4886, 0.5158, 0.5267,\n",
            "        0.5183, 0.5251, 0.4939, 0.5092, 0.5408, 0.4267, 0.4645, 0.5221, 0.5587,\n",
            "        0.4917, 0.5142, 0.4762, 0.4839, 0.4837, 0.4937, 0.4671, 0.4898, 0.5195,\n",
            "        0.4942, 0.4938, 0.4783, 0.4796, 0.5454, 0.4686, 0.5112, 0.5717, 0.5081,\n",
            "        0.4588, 0.5151, 0.4970, 0.4649, 0.5143, 0.5019, 0.5053, 0.4928, 0.5278,\n",
            "        0.5332, 0.5121, 0.4882, 0.4992, 0.5197, 0.4865, 0.5028, 0.4908, 0.4975,\n",
            "        0.4808])\n"
          ]
        }
      ],
      "source": [
        "output_pytorch = F.scaled_dot_product_attention(query, key, value)\n",
        "print(output_pytorch.shape)\n",
        "print(output_pytorch[0, 0, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjsviaZhkaU5",
        "outputId": "43eb4213-398f-4020-f5cd-e40e2e867b63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Does this have learnable parameters?\n",
        "output_pytorch.requires_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4j-VvKEpZVI",
        "outputId": "80ad0107-0cd5-471d-b81c-f374e3bf3a6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 8, 128, 128])\n",
            "torch.Size([32, 8, 64, 128])\n",
            "torch.Size([32, 8, 64, 128])\n",
            "tensor(64)\n",
            "torch.Size([]) torch.Size([32, 8, 128, 128]) torch.Size([32, 8, 128, 64])\n",
            "torch.Size([32, 8, 128, 128]) torch.Size([32, 8, 64, 128])\n",
            "torch.Size([32, 8, 128, 64])\n"
          ]
        }
      ],
      "source": [
        "def attention(query, key, value):\n",
        "  d_k = torch.tensor(query.shape[-1]) # torch.sqrt needs a tensor\n",
        "  print(torch.matmul(query, key.mT).shape)\n",
        "  print(key.mT.shape)\n",
        "  print(key.transpose(-2, -1).shape)\n",
        "\n",
        "  # tensor.mT is equivalent to tensor.transpose(-2, -1), see: https://pytorch.org/docs/stable/tensors.html#torch.Tensor.mT\n",
        "  # -> last two dimensions reversed\n",
        "  q_k = F.softmax(torch.matmul(query, key.mT)/torch.sqrt(d_k), dim=-1)\n",
        "\n",
        "  print(d_k)\n",
        "\n",
        "  print(d_k.shape, q_k.shape, value.shape)\n",
        "  print(q_k.shape, value.mT.shape)\n",
        "\n",
        "  return torch.matmul(q_k, value)\n",
        "\n",
        "output_custom = attention(query, key, value)\n",
        "print(output_pytorch.shape)\n",
        "# print(output_pytorch[0, 0, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axD45MIHpO3y"
      },
      "outputs": [],
      "source": [
        "# Assert all of the output values are close\n",
        "assert torch.all(output_custom.isclose(output_pytorch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdMSi7b2Xtgw"
      },
      "source": [
        "## TODO: Why \"self\" attention\n",
        "\n",
        "TL;DR given a sequence, which parts of the sequence are most important based on the sequence itself\n",
        "\n",
        "Self-attention = based on its own input how should its representation differ\n",
        "\n",
        "Eg the word “cup” should have a different representation given the sentences:\n",
        "\n",
        "* “England won the World Cup”\n",
        "* “I filled my cup with orange juice”\n",
        "\n",
        "Same word, but different contexts - self-attention will adjust the weight values given the other items in the context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSuilD4enBZI"
      },
      "source": [
        "## TODO: Make it learnable\n",
        "\n",
        "* TK - make this section more clear\n",
        "* TK - see section 3.2.2 Multi-Head Attention for \"where the **projections** are parameter matrics `WQ`, `WK`, `WV` etc\n",
        "  * Projections = learnable embedding = linear projection\n",
        "\n",
        "Okay cool, we've replicated PyTorch's `scaled_dot_product_attention`.\n",
        "\n",
        "But right now it's just a static operaton.\n",
        "\n",
        "And the whole goal of machine learning is to write algortihms that *learn* over time.\n",
        "\n",
        "So we need to make a learnable version of attention mechansim.\n",
        "\n",
        "How?\n",
        "\n",
        "Projections!\n",
        "\n",
        "What?\n",
        "\n",
        "Projections into embedding space.\n",
        "\n",
        "An embedding is a learnable representation of something.\n",
        "\n",
        "And so instead of a static vector representing our data, we can turn it into an embedding and create a *learnable vector* (a vector that changes over time given new information)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWfQxB2jnBNi",
        "outputId": "c12c485b-d573-4f0f-9d32-96dd72c3a830"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x input shape: torch.Size([32, 128, 512])\n",
            "qkv shape: torch.Size([32, 128, 1536])\n",
            "qkv shape: torch.Size([3, 32, 128, 512])\n",
            "q shape: torch.Size([32, 128, 512]) | k shape: torch.Size([32, 128, 512]) | v shape: torch.Size([32, 128, 512])\n",
            "q_k shape: torch.Size([32, 128, 128])\n",
            "q_k_scale_softmax_v output shape: torch.Size([32, 128, 512])\n",
            "x output shape: torch.Size([32, 128, 512])\n"
          ]
        }
      ],
      "source": [
        "class SelfAttentionLearnable(nn.Module):\n",
        "  def __init__(self, embed_dim):\n",
        "    super().__init__()\n",
        "    self.embed_dim = embed_dim\n",
        "    self.scale = embed_dim ** -0.5 # power of -0.5 == same as square root\n",
        "\n",
        "    # TK - one option = make one big projection (e.g. embed_dim * 3), then reshape = faster (on bigger GPUs)\n",
        "    # TK - another option = make one projection per Q, K, V\n",
        "\n",
        "    # Create a projection (learnable embedding)\n",
        "    self.qkv = nn.Linear(in_features=embed_dim,\n",
        "                         out_features=embed_dim * 3, # one per Q, K, V\n",
        "                         bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B, N, _ = x.shape\n",
        "\n",
        "    # Do the projection\n",
        "    qkv = self.qkv(x)\n",
        "    print(f\"qkv shape: {qkv.shape}\")\n",
        "\n",
        "    # qkv = qkv.reshape(B, N, 3, self.embed_dim).permute(1, # qkv\n",
        "    #                                                    0, # batch\n",
        "    #                                                    2, # num_tokens\n",
        "    #                                                    3) # embed_dim\n",
        "\n",
        "    qkv = qkv.reshape(B, N, 3, self.embed_dim).permute(2, # qkv\n",
        "                                                       0, # batch\n",
        "                                                       1, # num_tokens\n",
        "                                                       3) # embed_dim\n",
        "\n",
        "    print(f\"qkv shape: {qkv.shape}\")\n",
        "\n",
        "    # TODO: replace the above with einops?\n",
        "\n",
        "    q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "    print(f\"q shape: {q.shape} | k shape: {k.shape} | v shape: {v.shape}\")\n",
        "\n",
        "    # Perform self-attention (self = the operation happens on itself)\n",
        "    q_k = torch.matmul(q, k.mT)\n",
        "    print(f\"q_k shape: {q_k.shape}\")\n",
        "\n",
        "    q_k_scale = q_k * self.scale\n",
        "\n",
        "    # Softmax on embedding dim (last dim)\n",
        "    q_k_scale_softmax = torch.softmax(q_k_scale, dim=-1)\n",
        "\n",
        "    # Pefrom final batch mm\n",
        "    q_k_scale_softmax_v = torch.matmul(q_k_scale_softmax, v)\n",
        "\n",
        "    print(f\"q_k_scale_softmax_v output shape: {q_k_scale_softmax_v.shape}\")\n",
        "\n",
        "    # TODO: Try this with einops rearrange\n",
        "    x = q_k_scale_softmax_v.transpose(1, 2).reshape(B, N, self.embed_dim)\n",
        "\n",
        "    print(f\"x output shape: {x.shape}\")\n",
        "\n",
        "    return x\n",
        "\n",
        "embed_dim = 512\n",
        "batch_size = 32\n",
        "num_tokens = 128\n",
        "attention_learnable = SelfAttentionLearnable(embed_dim=embed_dim)\n",
        "x = torch.arange(batch_size*num_tokens*embed_dim, dtype=torch.float32).reshape(batch_size, num_tokens, embed_dim)\n",
        "print(f\"x input shape: {x.shape}\")\n",
        "x_out = attention_learnable(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mluQ_7rIzI8r"
      },
      "source": [
        "Now try learnable attention with einops..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vp07fMCzMxh"
      },
      "outputs": [],
      "source": [
        "# What about einops?\n",
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMSsOgyxzaVN"
      },
      "outputs": [],
      "source": [
        "from einops import rearrange, reduce, repeat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxH9hueBzNLJ",
        "outputId": "f95ad63d-bf83-44da-8fe8-1e02fe68dad8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x input shape: torch.Size([32, 128, 512])\n",
            "q shape: torch.Size([32, 128, 512]) | k shape: torch.Size([32, 128, 512]) | v shape: torch.Size([32, 128, 512])\n",
            "q_k shape: torch.Size([32, 128, 128])\n",
            "q_k_scale_softmax_v output shape: torch.Size([32, 128, 512])\n",
            "x output shape: torch.Size([32, 128, 512])\n"
          ]
        }
      ],
      "source": [
        "class SelfAttentionLearnable(nn.Module):\n",
        "  def __init__(self, embed_dim):\n",
        "    super().__init__()\n",
        "    self.embed_dim = embed_dim\n",
        "    self.scale = embed_dim ** -0.5 # power of -0.5 == same as square root\n",
        "\n",
        "    # Create a projection (learnable embedding) for each input (x -> Q, K, V)\n",
        "    self.q_projection = nn.Linear(in_features=embed_dim,\n",
        "                                  out_features=embed_dim,\n",
        "                                  bias=False)\n",
        "\n",
        "    self.k_projection = nn.Linear(in_features=embed_dim,\n",
        "                                  out_features=embed_dim,\n",
        "                                  bias=False)\n",
        "\n",
        "    self.v_projection = nn.Linear(in_features=embed_dim,\n",
        "                                  out_features=embed_dim,\n",
        "                                  bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B, N, _ = x.shape\n",
        "\n",
        "    # Do the projection(s)\n",
        "    q = self.q_projection(x)\n",
        "    k = self.k_projection(x)\n",
        "    v = self.v_projection(x)\n",
        "\n",
        "    print(f\"q shape: {q.shape} | k shape: {k.shape} | v shape: {v.shape}\")\n",
        "\n",
        "    # Perform self-attention (self = the operation happens on itself)\n",
        "    q_k = torch.matmul(q, k.mT)\n",
        "    print(f\"q_k shape: {q_k.shape}\")\n",
        "\n",
        "    q_k_scale = q_k * self.scale\n",
        "\n",
        "    # Softmax on embedding dim (last dim)\n",
        "    q_k_scale_softmax = torch.softmax(q_k_scale, dim=-1)\n",
        "\n",
        "    # Pefrom final batch mm\n",
        "    q_k_scale_softmax_v = torch.matmul(q_k_scale_softmax, v)\n",
        "\n",
        "    print(f\"q_k_scale_softmax_v output shape: {q_k_scale_softmax_v.shape}\")\n",
        "\n",
        "    # # TODO: Try this with einops rearrange\n",
        "    # x = q_k_scale_softmax_v.transpose(1, 2).reshape(B, N, self.embed_dim)\n",
        "\n",
        "    print(f\"x output shape: {x.shape}\")\n",
        "\n",
        "    return x\n",
        "\n",
        "embed_dim = 512\n",
        "batch_size = 32\n",
        "num_tokens = 128\n",
        "attention_learnable = SelfAttentionLearnable(embed_dim=embed_dim)\n",
        "x = torch.arange(batch_size*num_tokens*embed_dim, dtype=torch.float32).reshape(batch_size, num_tokens, embed_dim)\n",
        "print(f\"x input shape: {x.shape}\")\n",
        "x_out = attention_learnable(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WGbzrk91Q1N"
      },
      "outputs": [],
      "source": [
        "# UPTOHERE:\n",
        "# Replace forward() with F.scaled_dot_product_attention...\n",
        "# by the end you should know the attention formula off by heart (it's not too hard... a few variables + a few operations), getting the shapes to line up is the hard part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yl2estiVb9ht"
      },
      "outputs": [],
      "source": [
        "class SelfAttentionLearnableCustom(nn.Module):\n",
        "  def __init__(self, embed_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.embed_dim = embed_dim\n",
        "\n",
        "    # Create scale\n",
        "    self.scale = embed_dim ** -0.5\n",
        "\n",
        "    # Create projections\n",
        "    self.query_projection = nn.Linear(in_features=embed_dim,\n",
        "                                      out_features=embed_dim,\n",
        "                                      bias=False)\n",
        "\n",
        "    self.key_projection = nn.Linear(in_features=embed_dim,\n",
        "                                    out_features=embed_dim,\n",
        "                                    bias=False)\n",
        "\n",
        "    self.value_projection = nn.Linear(in_features=embed_dim,\n",
        "                                      out_features=embed_dim,\n",
        "                                      bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    query, key, value = self.query_projection(x), self.key_projection(x), self.value_projection(x)\n",
        "\n",
        "    # Perform scaled_dot_production_attention\n",
        "    attn = attention(query=query,\n",
        "                     key=key,\n",
        "                     value=value)\n",
        "\n",
        "    return attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tETWkPQRYOiU"
      },
      "outputs": [],
      "source": [
        "class SelfAttentionLearnablePyTorch(nn.Module):\n",
        "  def __init__(self, embed_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.embed_dim = embed_dim\n",
        "\n",
        "    # Create scale\n",
        "    self.scale = embed_dim ** -0.5\n",
        "\n",
        "    # Create projections\n",
        "    self.query_projection = nn.Linear(in_features=embed_dim,\n",
        "                                      out_features=embed_dim,\n",
        "                                      bias=False)\n",
        "\n",
        "    self.key_projection = nn.Linear(in_features=embed_dim,\n",
        "                                    out_features=embed_dim,\n",
        "                                    bias=False)\n",
        "\n",
        "    self.value_projection = nn.Linear(in_features=embed_dim,\n",
        "                                      out_features=embed_dim,\n",
        "                                      bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    query, key, value = self.query_projection(x), self.key_projection(x), self.value_projection(x)\n",
        "\n",
        "    # Perform scaled_dot_production_attention\n",
        "    attn = F.scaled_dot_product_attention(query=query,\n",
        "                                          key=key,\n",
        "                                          value=value)\n",
        "\n",
        "    return attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU9lDyWtaIGQ",
        "outputId": "7a8dc2ac-c540-4010-c96b-d313c9e65cc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x input shape: torch.Size([32, 128, 512])\n",
            "torch.Size([32, 128, 128])\n",
            "torch.Size([32, 512, 128])\n",
            "torch.Size([32, 512, 128])\n",
            "tensor(512)\n",
            "torch.Size([]) torch.Size([32, 128, 128]) torch.Size([32, 128, 512])\n",
            "torch.Size([32, 128, 128]) torch.Size([32, 512, 128])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(torch.Size([32, 128, 512]), torch.Size([32, 128, 512]))"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make sure the outcomes are the same\n",
        "\n",
        "torch.manual_seed(42)\n",
        "self_attention_custom = SelfAttentionLearnableCustom(embed_dim=512)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "self_attention_pytorch = SelfAttentionLearnablePyTorch(embed_dim=512)\n",
        "\n",
        "x = torch.arange(batch_size*num_tokens*embed_dim, dtype=torch.float32).reshape(batch_size, num_tokens, embed_dim)\n",
        "print(f\"x input shape: {x.shape}\")\n",
        "\n",
        "x_out_custom = self_attention_custom(x)\n",
        "\n",
        "x_out_pytorch = self_attention_pytorch(x)\n",
        "x_out_custom.shape, x_out_pytorch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7vRLOBwc0si",
        "outputId": "e8d07a50-c096-4042-a72a-961cf4201564"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(104.0217, grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_out_pytorch[0][0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eryYLIGacxut",
        "outputId": "73fa12ff-6450-4c03-e101-cc73b3f17bb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(104.0217, grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_out_custom[0][0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpkbkprHcYOZ",
        "outputId": "5f3bcd12-bb62-4463-aef6-9c480bb81fea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.all(x_out_custom.isclose(x_out_pytorch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71vKVcG4l54t"
      },
      "source": [
        "## TODO: A cool trick with `einops`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZrCXRCQucfh"
      },
      "outputs": [],
      "source": [
        "# What about einops?\n",
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWU9f--huvnB"
      },
      "outputs": [],
      "source": [
        "from einops import rearrange, reduce, repeat\n",
        "\n",
        "print(f\"Key shape: {key.shape} [batch, num_heads, input_sequence, embedding_dim]\")\n",
        "\n",
        "### The following all do the same ###\n",
        "\n",
        "# Rearrange the shape for our use case\n",
        "key_rearranged = rearrange(key, 'batch heads input embed -> batch heads embed input')\n",
        "\n",
        "# Key tranposed\n",
        "key_transposed = key.transpose(-2, -1)\n",
        "\n",
        "# Key mT (note: use .mT rather than .T on tensors with more than two dimensions)\n",
        "key_mt = key.mT\n",
        "\n",
        "print(key_rearranged.shape, key_transposed.shape, key_mt.shape)\n",
        "assert key_rearranged.shape == key_transposed.shape == key_mt.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81KIT2MtYKyH"
      },
      "source": [
        "## TODO: Why multi-head attention?\n",
        "\n",
        "TL;DR more opportunities to learn (e.g. 8x64 scaled dot-product attention = better than 1*512)\n",
        "\n",
        "TK:\n",
        "- One big matrix multiplication better than lots of small ones\n",
        "- Just perform a `nn.Linear()` then break it up\n",
        "- Implementing multi-head attention gives you self-attention, because you just use 1 head (versus multiple)\n",
        "\n",
        "**Goal:** Replicate PyTorch's `torch.nn.MultiheadAttention()` - https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InUnaU5hYY4i",
        "outputId": "4f001e52-22e1-42f6-eff0-f9ec2c687065"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([32, 128, 512]),\n",
              " torch.Size([32, 128, 512]),\n",
              " torch.Size([32, 128, 128]))"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_head_attention_pytorch = torch.nn.MultiheadAttention(embed_dim=512,\n",
        "                                                           num_heads=8,\n",
        "                                                           batch_first=True, # Does your batch dimension come first?\n",
        "                                                           )\n",
        "\n",
        "attn_output, attn_output_weights = multi_head_attention_pytorch(query=x, key=x, value=x,\n",
        "                                                                need_weights=True) # Return weights or not\n",
        "x.shape, attn_output.shape, attn_output_weights.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeGA5DWonxm5",
        "outputId": "dee96b03-9a59-4f15-ea9f-44c980b248c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attn_output.requires_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9E0YNtvgZpa",
        "outputId": "60cddc76-f04f-4a3e-e1f9-97f8c724e51f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query shape: torch.Size([32, 128, 512]) | Key shape: torch.Size([32, 128, 512]) | Value shape: torch.Size([32, 128, 512])\n",
            "Query shape (heads): torch.Size([32, 128, 8, 64]) | Key shape (heads): torch.Size([32, 128, 8, 64]) | Value shape (heads): torch.Size([32, 128, 8, 64])\n",
            "Out shape: torch.Size([32, 128, 8, 64])\n",
            "Concat shape: torch.Size([32, 128, 512])\n",
            "Projection out shape: torch.Size([32, 128, 512])\n"
          ]
        }
      ],
      "source": [
        "# TK - embed_dim, num_heads = minimum viable variables (masking can come later)\n",
        "class MultiheadAttentionCustom(nn.Module):\n",
        "  def __init__(self,\n",
        "               embed_dim,\n",
        "               num_heads,\n",
        "               # TK - dropout\n",
        "               ):\n",
        "    super().__init__()\n",
        "    self.embed_dim = embed_dim\n",
        "    self.num_heads = num_heads\n",
        "\n",
        "    assert embed_dim % num_heads == 0, \"Embedding dimension must be divisible by number of heads\"\n",
        "\n",
        "    self.head_dim = embed_dim // num_heads\n",
        "    self.scale = self.head_dim ** -0.5 # \"to the power\" is same as squareroot\n",
        "\n",
        "    self.softmax = nn.Softmax(dim=-1) # perform softmax on embedding dim (last dim)\n",
        "\n",
        "    # TK - see bias parameter in docs: https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html\n",
        "    # \"bias – If specified, adds bias to input / output projection layers. Default: True.\"\n",
        "    self.query_projection = nn.Linear(embed_dim, embed_dim, bias=True)\n",
        "    self.key_projection = nn.Linear(embed_dim, embed_dim, bias=True)\n",
        "    self.value_projection = nn.Linear(embed_dim, embed_dim, bias=True)\n",
        "\n",
        "    # Project out\n",
        "    self.project_out = nn.Linear(embed_dim, embed_dim, bias=True)\n",
        "\n",
        "    # TODO: dropout\n",
        "    # TODO: masking\n",
        "\n",
        "  def forward(self, x):\n",
        "    batch_size, num_tokens, embed_dim = x.shape\n",
        "\n",
        "    # Project_in (linear)\n",
        "    query, key, value = self.query_projection(x), self.key_projection(x), self.value_projection(x)\n",
        "\n",
        "    print(f\"Query shape: {query.shape} | Key shape: {key.shape} | Value shape: {value.shape}\")\n",
        "\n",
        "    # Convert to num heads\n",
        "    query = query.reshape(batch_size, num_tokens, self.num_heads, self.head_dim)\n",
        "    key = key.reshape(batch_size, num_tokens, self.num_heads, self.head_dim)\n",
        "    value = value.reshape(batch_size, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "    print(f\"Query shape (heads): {query.shape} | Key shape (heads): {key.shape} | Value shape (heads): {value.shape}\")\n",
        "\n",
        "    # self-attention * heads = softmax((<q, k>)/d_k))v\n",
        "    dots = torch.matmul(query, key.mT) * self.scale\n",
        "    attn = self.softmax(dots)\n",
        "    out = torch.matmul(attn, value)\n",
        "\n",
        "    print(f\"Out shape: {out.shape}\")\n",
        "\n",
        "    # TODO: dropout\n",
        "\n",
        "    # Concat last two dims together\n",
        "    concat = out.reshape(batch_size, num_tokens, embed_dim)\n",
        "    print(f\"Concat shape: {concat.shape}\")\n",
        "\n",
        "    # project_out (linear)\n",
        "    x_out = self.project_out(concat)\n",
        "    print(f\"Projection out shape: {x_out.shape}\")\n",
        "\n",
        "    return x_out\n",
        "\n",
        "\n",
        "multihead_attention_custom = MultiheadAttentionCustom(embed_dim=512, num_heads=8)\n",
        "x_multihead_out_custom = multihead_attention_custom(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcKRix-OrC7K",
        "outputId": "a43a2276-3f4a-4272-f790-354df10f8c91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x input shape: torch.Size([32, 128, 512])\n",
            "Query shape: torch.Size([32, 128, 512]) | Key shape: torch.Size([32, 128, 512]) | Value shape: torch.Size([32, 128, 512])\n",
            "Query shape (heads): torch.Size([32, 128, 8, 64]) | Key shape (heads): torch.Size([32, 128, 8, 64]) | Value shape (heads): torch.Size([32, 128, 8, 64])\n",
            "Out shape: torch.Size([32, 128, 8, 64])\n",
            "Concat shape: torch.Size([32, 128, 512])\n",
            "Projection out shape: torch.Size([32, 128, 512])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(batch_size*num_tokens*embed_dim, dtype=torch.float32).reshape(batch_size, num_tokens, embed_dim)\n",
        "print(f\"x input shape: {x.shape}\")\n",
        "\n",
        "torch.manual_seed(42)\n",
        "multi_head_attention_pytorch = torch.nn.MultiheadAttention(embed_dim=512,\n",
        "                                                           num_heads=8,\n",
        "                                                           batch_first=True, # Does your batch dimension come first?\n",
        "                                                           )\n",
        "\n",
        "\n",
        "torch.manual_seed(42)\n",
        "multihead_attention_custom = MultiheadAttentionCustom(embed_dim=512, num_heads=8)\n",
        "\n",
        "\n",
        "x_attn_output_pytorch, attn_output_weights = multi_head_attention_pytorch(query=x, key=x, value=x,\n",
        "                                                                need_weights=True) # Return weights or not\n",
        "\n",
        "x_multihead_out_custom = multihead_attention_custom(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b8UOfBYsWhq",
        "outputId": "426e6b41-5ece-4f84-e778-f0e3110b3522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 128, 512])\n",
            "torch.Size([32, 128, 512])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "execution_count": 186,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(x_attn_output_pytorch.shape), print(x_multihead_out_custom.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bexbdvBisu4a",
        "outputId": "5da08e1c-cc50-498e-ae5a-057d69eb4db7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(16859.5352, grad_fn=<SelectBackward0>),\n",
              " tensor(-68.8901, grad_fn=<SelectBackward0>))"
            ]
          },
          "execution_count": 187,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_attn_output_pytorch[0][0][0], x_multihead_out_custom[0][0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UepiHy66s12i",
        "outputId": "81d96eaf-09df-4b65-b16a-82e6688ab3e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(False)"
            ]
          },
          "execution_count": 188,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TK - make sure these are close\n",
        "torch.all(x_attn_output_pytorch.isclose(x_multihead_out_custom))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JE4Bzkis858"
      },
      "outputs": [],
      "source": [
        "# Next:\n",
        "# Go through attention = simple version\n",
        "# Go through attention -> replicate PyTorch scaled_dot_product_attention\n",
        "# Go through attention -> replicate masking\n",
        "# Make it learnable\n",
        "# Make it multi-head (multi-head can be the same as single head if you code it to be so...)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMbnbfX9K09me6ubTS7xg68",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
