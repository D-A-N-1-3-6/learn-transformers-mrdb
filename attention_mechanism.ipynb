{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbnbfX9K09me6ubTS7xg68",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbourke/learn-transformers/blob/main/attention_mechanism.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [WIP] Attention mechanism\n",
        "\n",
        "**Focus:** Build intuition to build up to replicating the original Transformer paper.\n",
        "\n",
        "### This notebook\n",
        "\n",
        "* Recreate self-attention as per Transformer paper\n",
        "* Recreate multi-head attention as per Transformer paper\n",
        "\n",
        "### Later\n",
        "* Recreate Transformer model architecture\n",
        "* Train on a simple example\n",
        "\n",
        "Sources:\n",
        "\n",
        "* Transformer paper: https://arxiv.org/abs/1706.03762\n",
        "* The annotated transformer: http://nlp.seas.harvard.edu/2018/04/01/attention.html\n",
        "* https://lilianweng.github.io/posts/2018-06-24-attention/#self-attention\n",
        "* https://jaykmody.com/blog/attention-intuition/\n",
        "* Compact transformers - https://medium.com/pytorch/training-compact-transformers-from-scratch-in-30-minutes-with-pytorch-ff5c21668ed5\n",
        "* Implemented MHA - https://nn.labml.ai/transformers/mha.html"
      ],
      "metadata": {
        "id": "usdE3sRsGnj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What we're going to do\n",
        "\n",
        "Simple goals:\n",
        "\n",
        "Replicate the following functions/modules as fast as possible:\n",
        "* PyTorch's `scaled_dot_product_attention` - https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html\n",
        "  * Explain the intuition of the attention mechanism\n",
        "* PyTorch's MultiHeadAttention - https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html\n",
        "  * Both of these are the same equations used in the Transformer paper\n",
        "* Do with and without masking\n",
        "* Use these to build on the next chatper: replicating the Transformer architecture\n",
        "  * Focus on what the inputs and outputs should be (e.g. text/vision/audio, in essence, seq2seq)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b5lKkczcnUaI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "6-XaYYv9GcKP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple scaled-dot-product-attention (no mask)\n",
        "\n",
        "Attention formula = `softmax((Q, K.T)/torch.sqrt(d_k))V`\n",
        "\n",
        "$$\n",
        "\\operatorname{Attention}(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{\\mathrm{T}}}{\\sqrt{d_k}}\\right) V\n",
        "$$\n",
        "\n",
        "TK:\n",
        "- Explain what each of these values are\n",
        "\n",
        "TK:\n",
        "- Can I replicate this in Google Sheets?... yes I can... kind of (except for softmax, etc)\n",
        "- Turn this function into the same format as the transformer paper (e.g. figure 2)"
      ],
      "metadata": {
        "id": "RvO_nyA2O6tZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def attention(query, key, value):\n",
        "\n",
        "  # Create the scale factor (sqrt(d_k))\n",
        "  d_k = torch.sqrt(torch.tensor(query.shape[-1])) # torch.sqrt needs a tensor\n",
        "\n",
        "  q_k = torch.matmul(query, key.mT) # .mT = matrix Transpose (transposes the last two dimensions)\n",
        "  q_k_softmax_scale = F.softmax(q_k/torch.sqrt(d_k), dim=-1)\n",
        "  q_k_softmax_scale_v = torch.matmul(q_k, value)\n",
        "  return q_k_softmax_scale_v"
      ],
      "metadata": {
        "id": "nMVXnybZGhun"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "x = torch.randn(3, 3)\n",
        "\n",
        "output_custom = attention(query=x, key=x, value=x)\n",
        "output_custom"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWgiQ8HWHjcK",
        "outputId": "0bbed3de-97f4-4c79-8572-eaf1f81fdcae"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.7361, -0.3428,  0.4193],\n",
              "        [ 2.7884, -2.2552,  0.2486],\n",
              "        [12.6584, -4.6864,  2.5056]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Does this equal PyTorch's scaled_dot_product_attention?\n",
        "output_pytorch = F.scaled_dot_product_attention(query=x,\n",
        "                                                key=x,\n",
        "                                                value=x)\n",
        "output_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESpNb90liTrw",
        "outputId": "a90c0651-fc06-4b4f-dbd6-50c8cf2f317c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.1175, -0.5276,  0.2233],\n",
              "        [ 1.0066, -0.7048,  0.1397],\n",
              "        [ 1.9621, -0.6285,  0.4030]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Should output true\n",
        "torch.all(output_pytorch.isclose(output_custom))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRLh4GQ9ihdk",
        "outputId": "de685fec-fda2-4efc-a4ef-72dfcedf41c6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(False)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO: What is a query, key and value?\n",
        "\n",
        "* What if I told you you already know about the attention mechanism?... and your local cafe owner knows it very well\n",
        "\n",
        "* Give an example of different values input and output into our attention mechansim\n",
        "\n",
        "TK - Can I do sales of different products? Does this relate?\n",
        "\n",
        "E.g.\n",
        "* query = sales on monday\n",
        "* key = product\n",
        "* value = amount?\n",
        "\n",
        "Does this work??"
      ],
      "metadata": {
        "id": "0Kxahii5xJRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: finalize this and upload it to GitHub (if it works)\n",
        "!wget https://www.dropbox.com/s/8heqlnrpkf7tlbq/cafe_sales_data_csv.xlsx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VbBzoBOxLj_",
        "outputId": "aa69d682-e4c2-453d-b0ef-d1f57171eeef"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-22 04:29:37--  https://www.dropbox.com/s/8heqlnrpkf7tlbq/cafe_sales_data_csv.xlsx\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/8heqlnrpkf7tlbq/cafe_sales_data_csv.xlsx [following]\n",
            "--2023-06-22 04:29:38--  https://www.dropbox.com/s/raw/8heqlnrpkf7tlbq/cafe_sales_data_csv.xlsx\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucaaa66052d2ea5841481738994c.dl.dropboxusercontent.com/cd/0/inline/B-fn1PL0NrbwcxY2vKAUHunGDt4Pn_2aC3IgHfKBU2ZMprzCkvEJXIyBVCjd4IYtWRmaKWZQuFTw10xWkYmhEcnja2Pzaz3MIFjGiq_nw_UEa_RyRnjHtpPL6poLjKffzWjk6BKb9ZraJvK5Jaahm1M7wO8YNYDd6FwBkap4utjScg/file# [following]\n",
            "--2023-06-22 04:29:38--  https://ucaaa66052d2ea5841481738994c.dl.dropboxusercontent.com/cd/0/inline/B-fn1PL0NrbwcxY2vKAUHunGDt4Pn_2aC3IgHfKBU2ZMprzCkvEJXIyBVCjd4IYtWRmaKWZQuFTw10xWkYmhEcnja2Pzaz3MIFjGiq_nw_UEa_RyRnjHtpPL6poLjKffzWjk6BKb9ZraJvK5Jaahm1M7wO8YNYDd6FwBkap4utjScg/file\n",
            "Resolving ucaaa66052d2ea5841481738994c.dl.dropboxusercontent.com (ucaaa66052d2ea5841481738994c.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601b:15::a27d:80f\n",
            "Connecting to ucaaa66052d2ea5841481738994c.dl.dropboxusercontent.com (ucaaa66052d2ea5841481738994c.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B-frQBNBfaB73ugZQd9yl8hVsqW_TAVv8ABTQHyjBxHFfnfn_C0JQd854nuisIe3hh7_Sf2-4f-VRWCk5Zd0Jy6Ey61ehGZ9ExXVZAZYc_8sWA8s7tQNz6H4U0GGBcX06i_C9_IdUHVZ8yPX5v6AUJX-OHJrMsqhA0LJsKzepjpkUZmgT8YNDu-ZFUVAxdtM3pvsbTnuK3gKGEgZuGhNF7AhUYpXTdUM7Mi3TGZbTagGuwOoWw4GAzWOUFWDHReOLH46JVoRl1w6U8baIEm9wLrEu6UBIx6VNC4BB8zMZPvnLP_KXQypq9NyEWciAOGHYwNFzMlIqJPnE0SWb4Sr1ji0RggWacfe9zk-QKBIJrAvT0aUU0g_uTt2ksLA3eJlnnr4mKXupvRKxFZ02g9TAphWkpFS2k_H4wa26dN8ITm3ZQ/file [following]\n",
            "--2023-06-22 04:29:38--  https://ucaaa66052d2ea5841481738994c.dl.dropboxusercontent.com/cd/0/inline2/B-frQBNBfaB73ugZQd9yl8hVsqW_TAVv8ABTQHyjBxHFfnfn_C0JQd854nuisIe3hh7_Sf2-4f-VRWCk5Zd0Jy6Ey61ehGZ9ExXVZAZYc_8sWA8s7tQNz6H4U0GGBcX06i_C9_IdUHVZ8yPX5v6AUJX-OHJrMsqhA0LJsKzepjpkUZmgT8YNDu-ZFUVAxdtM3pvsbTnuK3gKGEgZuGhNF7AhUYpXTdUM7Mi3TGZbTagGuwOoWw4GAzWOUFWDHReOLH46JVoRl1w6U8baIEm9wLrEu6UBIx6VNC4BB8zMZPvnLP_KXQypq9NyEWciAOGHYwNFzMlIqJPnE0SWb4Sr1ji0RggWacfe9zk-QKBIJrAvT0aUU0g_uTt2ksLA3eJlnnr4mKXupvRKxFZ02g9TAphWkpFS2k_H4wa26dN8ITm3ZQ/file\n",
            "Reusing existing connection to ucaaa66052d2ea5841481738994c.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5101 (5.0K) [application/vnd.openxmlformats-officedocument.spreadsheetml.sheet]\n",
            "Saving to: ‘cafe_sales_data_csv.xlsx’\n",
            "\n",
            "cafe_sales_data_csv 100%[===================>]   4.98K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-22 04:29:38 (528 MB/s) - ‘cafe_sales_data_csv.xlsx’ saved [5101/5101]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel(\"cafe_sales_data_csv.xlsx\") # TODO: read_excel with _csv in the filename is confusing...\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "p-wiDpW9xgVo",
        "outputId": "13f85468-70a9-4570-ff0d-9e102f3fa570"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Unnamed: 0  Monday  Tuesday  Wednesday  Thursday  Friday  Saturday  Sunday\n",
              "0     Coffee       0       50         55        68      91       107      84\n",
              "1      Bread       0       20         22        25      12        40      49\n",
              "2      Bacon       0       10         15        20      10        65      39\n",
              "3       Milk       0       15         15        18      16        51      45\n",
              "4      Bagel       0       21          8        20      60        56      44\n",
              "5   Sandwich       0        9          8        50      18        62      50\n",
              "6  Crossiant       0       11          4         3       7        49      55"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b44df945-eebe-4e43-8d81-9810690df323\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Monday</th>\n",
              "      <th>Tuesday</th>\n",
              "      <th>Wednesday</th>\n",
              "      <th>Thursday</th>\n",
              "      <th>Friday</th>\n",
              "      <th>Saturday</th>\n",
              "      <th>Sunday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Coffee</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>55</td>\n",
              "      <td>68</td>\n",
              "      <td>91</td>\n",
              "      <td>107</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bread</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>22</td>\n",
              "      <td>25</td>\n",
              "      <td>12</td>\n",
              "      <td>40</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bacon</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>65</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Milk</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>16</td>\n",
              "      <td>51</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bagel</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>60</td>\n",
              "      <td>56</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Sandwich</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>50</td>\n",
              "      <td>18</td>\n",
              "      <td>62</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Crossiant</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>49</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b44df945-eebe-4e43-8d81-9810690df323')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b44df945-eebe-4e43-8d81-9810690df323 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b44df945-eebe-4e43-8d81-9810690df323');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create price vector\n",
        "price_dict = {\n",
        "    \"coffee\": 5,\n",
        "    \"bread\": 8,\n",
        "    \"bacon\": 15,\n",
        "    \"milk\": 4,\n",
        "    \"bagel\": 9,\n",
        "    \"sandwich\": 12,\n",
        "    \"croissant\": 8\n",
        "}\n",
        "price_vector = torch.tensor(list(price_dict.values()), dtype=torch.float32)\n",
        "price_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o-GJZj-zWsg",
        "outputId": "fddfad36-8d31-4704-8ae1-48fc784de497"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5.,  8., 15.,  4.,  9., 12.,  8.])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sales matrix\n",
        "sales_matrix = torch.tensor(df.drop(\"Unnamed: 0\", axis=1).values, dtype=torch.float32)\n",
        "sales_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLZgRl5Dz51v",
        "outputId": "2e319b55-4edf-4d88-d1f8-e2ab631f3a59"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0.,  50.,  55.,  68.,  91., 107.,  84.],\n",
              "        [  0.,  20.,  22.,  25.,  12.,  40.,  49.],\n",
              "        [  0.,  10.,  15.,  20.,  10.,  65.,  39.],\n",
              "        [  0.,  15.,  15.,  18.,  16.,  51.,  45.],\n",
              "        [  0.,  21.,   8.,  20.,  60.,  56.,  44.],\n",
              "        [  0.,   9.,   8.,  50.,  18.,  62.,  50.],\n",
              "        [  0.,  11.,   4.,   3.,   7.,  49.,  55.]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Sales: {sales_matrix.shape} (seven products, seven days of week)\")\n",
        "print(f\"Prices: {price_vector.shape} (seven products)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S_HxbAn0dQ9",
        "outputId": "3378da72-ae13-47b0-e12f-3ac99976099d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sales: torch.Size([7, 7]) (seven products, seven days of week)\n",
            "Prices: torch.Size([7]) (seven products)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the sales per day\n",
        "price_vector.matmul(sales_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5FLeA5Z0HIa",
        "outputId": "33d58041-ad83-4bc7-8ff1-33347abede98"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   0., 1005.,  936., 1716., 1577., 3674., 3013.])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "price_vector.unsqueeze(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZtS_qvk8xDp",
        "outputId": "b1795b29-51c3-4650-da12-8a4627d31869"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.],\n",
              "        [ 8.],\n",
              "        [15.],\n",
              "        [ 4.],\n",
              "        [ 9.],\n",
              "        [12.],\n",
              "        [ 8.]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "price_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx-vuk0P8zr2",
        "outputId": "a3b098c4-968f-4c3b-8e8b-ffdb14fac107"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5.,  8., 15.,  4.,  9., 12.,  8.])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# WRONG: Sales per item per day\n",
        "price_vector * sales_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvmvVBmC809o",
        "outputId": "488fbb17-91e1-4717-a2ae-436c24f48140"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   0.,  400.,  825.,  272.,  819., 1284.,  672.],\n",
              "        [   0.,  160.,  330.,  100.,  108.,  480.,  392.],\n",
              "        [   0.,   80.,  225.,   80.,   90.,  780.,  312.],\n",
              "        [   0.,  120.,  225.,   72.,  144.,  612.,  360.],\n",
              "        [   0.,  168.,  120.,   80.,  540.,  672.,  352.],\n",
              "        [   0.,   72.,  120.,  200.,  162.,  744.,  400.],\n",
              "        [   0.,   88.,   60.,   12.,   63.,  588.,  440.]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CORRECT: Manipulate price vector before multiplying to sales matrix\n",
        "price_vector.unsqueeze(1) * sales_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBhJxz2I8k6v",
        "outputId": "dc1b296d-fd9d-4f33-c6e6-6825990d1423"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0., 250., 275., 340., 455., 535., 420.],\n",
              "        [  0., 160., 176., 200.,  96., 320., 392.],\n",
              "        [  0., 150., 225., 300., 150., 975., 585.],\n",
              "        [  0.,  60.,  60.,  72.,  64., 204., 180.],\n",
              "        [  0., 189.,  72., 180., 540., 504., 396.],\n",
              "        [  0., 108.,  96., 600., 216., 744., 600.],\n",
              "        [  0.,  88.,  32.,  24.,  56., 392., 440.]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TK note:\n",
        "# matmul = sum over dim=0 -> item sales per day\n",
        "# manual setup = sum over dim=1 -> item sales per week\n",
        "total_item_sales_per_week = torch.sum(price_vector.unsqueeze(1) * sales_matrix, dim=1)\n",
        "total_item_sales_per_week"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVAyGUxf1Gjh",
        "outputId": "cedd12b5-a4f7-47e3-9fcb-c3cdc619a39d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2275., 1344., 2385.,  640., 1881., 2364., 1032.])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_sales_per_day = torch.sum(price_vector.unsqueeze(1) * sales_matrix, dim=0)\n",
        "total_sales_per_day"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycUpMtzo3rM2",
        "outputId": "1711d553-b1e6-44d2-e63e-7bc0e2c61f9c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   0., 1005.,  936., 1716., 1577., 3674., 3013.])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: try einsum? or einops?"
      ],
      "metadata": {
        "id": "nkDxDRjy_ZXx"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YL5oCz54_Usa"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TK - try create an example for attention"
      ],
      "metadata": {
        "id": "lA8p_lGV6H6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a query (\"What are the sales on Wednesday?\")\n",
        "sales_on_wednesday_vector = torch.zeros(7) # days of week\n",
        "sales_on_wednesday_vector[2] = 1\n",
        "sales_on_wednesday_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SriEVG8E7B0I",
        "outputId": "725be710-b916-4393-cb44-8766875f7c89"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 1., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the sales matrix (key) to the query (Q * K.T)\n",
        "wednesday_sales = sales_on_wednesday_vector.matmul(sales_matrix.T)\n",
        "wednesday_sales"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO50157P7Bu2",
        "outputId": "b4185fb0-1a4e-4840-8567-6be31cc5579e"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([55., 22., 15., 15.,  8.,  8.,  4.])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why scale?\n",
        "\n",
        "Watch this... softmax blows it out of the water..."
      ],
      "metadata": {
        "id": "kLGf-DMcByHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(wednesday_sales, dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1pLOP90Bp0T",
        "outputId": "1233565b-9f74-4989-ef2e-0c008022f05a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000e+00, 4.6589e-15, 4.2484e-18, 4.2484e-18, 3.8740e-21, 3.8740e-21,\n",
              "        7.0955e-23])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now scale..."
      ],
      "metadata": {
        "id": "yEgKwEOsB2MN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wednesday_sales.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taUwRq-BB-ew",
        "outputId": "20a4fb7d-edc3-4414-94b4-c930051e004d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([7])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(wednesday_sales / torch.sqrt(torch.tensor(wednesday_sales.shape[0])), dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIYjdkbcB19e",
        "outputId": "b57eac29-517b-40ad-f16d-ad8f6b9b8416"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000e+00, 3.8293e-06, 2.7170e-07, 2.7170e-07, 1.9277e-08, 1.9277e-08,\n",
              "        4.2507e-09])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Still blown out of the water but better... (could normalize these values first)\n",
        "\n",
        "e.g.\n",
        "\n",
        "```python\n",
        "norm_tensor = (x - torch.min(x))/(torch.max(x) - torch.min(x))\n",
        "```"
      ],
      "metadata": {
        "id": "RTsvFYZKCVGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(wednesday_sales / torch.sqrt(torch.tensor(wednesday_sales.shape[0])), dim=0) @ price_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu04zf4YCM9t",
        "outputId": "eafefa4e-5755-4a63-f299-3e43d06b7a60"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.0000)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Total sales on Wednesday\n",
        "attention_to_pay_on_wednesdays = wednesday_sales @ price_vector # price_vector = value\n",
        "attention_to_pay_on_wednesdays"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuEgA-T46ed1",
        "outputId": "b08c6bce-f2c0-483f-bb99-29f49158cac2"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(936.)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TODO: Try normalizing values\n",
        "\n",
        "See:"
      ],
      "metadata": {
        "id": "y-Ca0y5UsAEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NEXT:\n",
        "# Try normalizing the tensor values and see how they change/improve stability\n",
        "# Softmax on values with large differences = blows larger values out of the water (e.g. 1.0 vs 1e-10... basically nothing)"
      ],
      "metadata": {
        "id": "kuowdQTzDiAN"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "min_max = MinMaxScaler()\n",
        "sales_matrix_normalized = min_max.fit(sales_matrix).transform(sales_matrix)\n",
        "sales_matrix_normalized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_5LMpFwsjIK",
        "outputId": "3e70f79a-6f3e-4d77-c3a0-c6af22e981b9"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        ],\n",
              "       [0.        , 0.26829268, 0.35294118, 0.33846154, 0.05952381,\n",
              "        0.        , 0.22222222],\n",
              "       [0.        , 0.02439024, 0.21568627, 0.26153846, 0.03571429,\n",
              "        0.37313433, 0.        ],\n",
              "       [0.        , 0.14634146, 0.21568627, 0.23076923, 0.10714286,\n",
              "        0.1641791 , 0.13333333],\n",
              "       [0.        , 0.29268293, 0.07843137, 0.26153846, 0.63095238,\n",
              "        0.23880597, 0.11111111],\n",
              "       [0.        , 0.        , 0.07843137, 0.72307692, 0.13095238,\n",
              "        0.32835821, 0.24444444],\n",
              "       [0.        , 0.04878049, 0.        , 0.        , 0.        ,\n",
              "        0.13432836, 0.35555556]])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def min_max_normalize_tensor(x):\n",
        "  \"\"\"\n",
        "  See: https://en.wikipedia.org/wiki/Feature_scaling#Rescaling_(min-max_normalization)\n",
        "  \"\"\"\n",
        "\n",
        "  return (x - torch.min(x)) / (torch.max(x) - torch.min(x))"
      ],
      "metadata": {
        "id": "y2trYpZ2sC5I"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxx7LY51tHyK",
        "outputId": "1ea73450-e9c7-4a4c-dd73-9da46c925a25"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5.,  8., 15.,  4.,  9., 12.,  8.])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sales_matrix_normalized = min_max_normalize_tensor(sales_matrix)\n",
        "price_vector_normalized = min_max_normalize_tensor(price_vector)\n",
        "sales_matrix_normalized, price_vector_normalized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdyBFi9LsODb",
        "outputId": "107adca3-90f1-4a1a-b57d-7a00b0e2ebfd"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0000, 0.4673, 0.5140, 0.6355, 0.8505, 1.0000, 0.7850],\n",
              "         [0.0000, 0.1869, 0.2056, 0.2336, 0.1121, 0.3738, 0.4579],\n",
              "         [0.0000, 0.0935, 0.1402, 0.1869, 0.0935, 0.6075, 0.3645],\n",
              "         [0.0000, 0.1402, 0.1402, 0.1682, 0.1495, 0.4766, 0.4206],\n",
              "         [0.0000, 0.1963, 0.0748, 0.1869, 0.5607, 0.5234, 0.4112],\n",
              "         [0.0000, 0.0841, 0.0748, 0.4673, 0.1682, 0.5794, 0.4673],\n",
              "         [0.0000, 0.1028, 0.0374, 0.0280, 0.0654, 0.4579, 0.5140]]),\n",
              " tensor([0.0909, 0.3636, 1.0000, 0.0000, 0.4545, 0.7273, 0.3636]))"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TODO: Try standardizing\n",
        "\n",
        "See: https://en.wikipedia.org/wiki/Feature_scaling#Standardization_(Z-score_Normalization)"
      ],
      "metadata": {
        "id": "4aWRusXYvd57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.std(x, dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTRH-apNwvjA",
        "outputId": "50d5f064-168e-45c8-87f8-6da92e5bec85"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.1125, 0.6311, 0.3288])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_tensor(x):\n",
        "  \"\"\"\n",
        "  See: https://en.wikipedia.org/wiki/Feature_scaling#Standardization_(Z-score_Normalization)\n",
        "  \"\"\"\n",
        "  return (x - torch.mean(x)) / torch.std(x)"
      ],
      "metadata": {
        "id": "fZRKiDpAtc-x"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_matrix_standardized = standardize_tensor(sales_matrix)\n",
        "price_vector_standardized = standardize_tensor(price_vector)\n",
        "price_vector_standardized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTez0hPFtu8W",
        "outputId": "bb908786-8c6b-4f6f-f308-6d80effd56d6"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.9730, -0.1871,  1.6467, -1.2350,  0.0748,  0.8608, -0.1871])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "price_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mITQQ6hxvlIa",
        "outputId": "dbf336c6-f3c0-4a74-8014-308bf644c6e3"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5.,  8., 15.,  4.,  9., 12.,  8.])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a query (\"What are the sales on Wednesday?\")\n",
        "sales_on_wednesday_vector = torch.zeros(7) # days of week\n",
        "sales_on_wednesday_vector[2] = 1\n",
        "sales_on_wednesday_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_oOeaPmwA6_",
        "outputId": "70e1f4a5-10c9-4328-867e-5f8dc9bee717"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 1., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sales_matrix_standardized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4E_ws9XxoDV",
        "outputId": "80909fe4-cbac-4801-c8d4-0ae01dc06f70"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1194,  0.7374,  0.9231,  1.4059,  2.2600,  2.8542,  2.0000],\n",
              "        [-1.1194, -0.3767, -0.3024, -0.1910, -0.6738,  0.3661,  0.7003],\n",
              "        [-1.1194, -0.7480, -0.5623, -0.3767, -0.7480,  1.2945,  0.3289],\n",
              "        [-1.1194, -0.5623, -0.5623, -0.4509, -0.5252,  0.7745,  0.5517],\n",
              "        [-1.1194, -0.3395, -0.8223, -0.3767,  1.1088,  0.9602,  0.5146],\n",
              "        [-1.1194, -0.7852, -0.8223,  0.7374, -0.4509,  1.1830,  0.7374],\n",
              "        [-1.1194, -0.7109, -0.9708, -1.0080, -0.8594,  0.7003,  0.9231]])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(sales_on_wednesday_vector.unsqueeze(0).matmul(sales_matrix_standardized.T)/7, dim=1) @ price_vector_standardized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKPYq8Ct1u7v",
        "outputId": "1cae4ad2-d161-4365-cfd1-77e728024aaf"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0365])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(sales_on_wednesday_vector.unsqueeze(0).matmul(sales_matrix.T)/7, dim=1) @ price_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl1v3T_T2LhR",
        "outputId": "b6ee919a-5e8b-4da8-bb46-77ff5926fdfb"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5.0707])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sales_on_monday = torch.zeros(7)\n",
        "sales_on_monday[0] = 1\n",
        "print(sales_on_monday)\n",
        "F.softmax(sales_on_monday.unsqueeze(0).matmul(sales_matrix.T)/7, dim=1) @ price_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_jXH4cR2VFu",
        "outputId": "ed3d2227-8c1c-496a-eb48-a2b79a70f4f6"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 0., 0., 0., 0., 0., 0.])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([8.7143])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Non-standardize"
      ],
      "metadata": {
        "id": "nvka9Z5y3kej"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_on_monday = torch.zeros(7)\n",
        "sales_on_monday[5] = 1\n",
        "print(sales_on_monday)\n",
        "F.softmax(sales_on_monday.unsqueeze(0).matmul(sales_matrix_standardized.T)/7, dim=1) @ price_vector_standardized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugNTSb3y3R_A",
        "outputId": "8ab98cbb-5333-4469-8e6f-00fb63d4a00f"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0., 0., 0., 0., 1., 0.])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0193])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "day_names = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
        "day_values = range(0, 7)\n",
        "day_dict = dict(zip(day_values, day_names))\n",
        "day_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHIuE8LG3-gB",
        "outputId": "1d645388-2c61-485a-8b4a-39b3e388917c"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Monday',\n",
              " 1: 'Tuesday',\n",
              " 2: 'Wednesday',\n",
              " 3: 'Thursday',\n",
              " 4: 'Friday',\n",
              " 5: 'Saturday',\n",
              " 6: 'Sunday'}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Non-standardize\n",
        "for i in range(7):\n",
        "  day_tensor = torch.zeros(7)\n",
        "  day_tensor[i] = 1\n",
        "  day_name = day_dict[i]\n",
        "\n",
        "  print(f\"\\nDay name: {day_name}\")\n",
        "  print(f\"Day tensor: {day_tensor}\")\n",
        "  # day_tensor_standardize = standardize_tensor(day_tensor)\n",
        "  d_k = day_tensor.shape[-1]\n",
        "  print(d_k)\n",
        "  attn_score = F.softmax(day_tensor.unsqueeze(1).matmul(sales_matrix.T)/torch.sqrt(torch.tensor(7)), dim=1) @ price_vector\n",
        "  print(f\"Attention score: {attn_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "lOffwA9T5KAl",
        "outputId": "c4f5d1b5-ce40-4c20-d343-9fabba920f13"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Day name: Monday\n",
            "Day tensor: tensor([1., 0., 0., 0., 0., 0., 0.])\n",
            "7\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-b4ad1a2c8a36>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0md_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mday_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mattn_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mday_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msales_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mprice_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Attention score: {attn_score}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (7x1 and 7x7)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize\n",
        "# TODO: does this work for the triangle matrix?\n",
        "# e.g. triangle down the left to bottom right corner\n",
        "for i in range(7):\n",
        "  day_tensor = torch.zeros(7)\n",
        "  day_tensor[i] = 1\n",
        "  day_name = day_dict[i]\n",
        "\n",
        "  print(f\"\\nDay name: {day_name}\")\n",
        "  print(f\"Day tensor: {day_tensor}\")\n",
        "  day_tensor_standardize = standardize_tensor(day_tensor)\n",
        "  attn_score = F.softmax(day_tensor_standardize.unsqueeze(0).matmul(sales_matrix_standardized.T)/torch.sqrt(torch.tensor(7)), dim=1) @ price_vector_standardized\n",
        "  print(f\"Attention score: {attn_score}\")"
      ],
      "metadata": {
        "id": "T_NZHBaP3yrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_days = torch.eye(7)\n",
        "\n",
        "attention(query=all_days,\n",
        "          key=sales_matrix,\n",
        "          value=price_vector)"
      ],
      "metadata": {
        "id": "trRr4ecr5wWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_days = torch.eye(7)\n",
        "all_days_standardized = standardize_tensor(all_days)\n",
        "\n",
        "attention(query=all_days_standardized,\n",
        "          key=sales_matrix_standardized,\n",
        "          value=price_vector_standardized.unsqueeze(1))"
      ],
      "metadata": {
        "id": "rkCmpcUU59Us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F.scaled_dot_product_attention(query=all_days_standardized,\n",
        "                               key=sales_matrix_standardized,\n",
        "                               value=price_vector_standardized.unsqueeze(1))"
      ],
      "metadata": {
        "id": "Ef98o0s87GsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WWh0w0Rq6WDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yw00WM556WAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "standardize_tensor_day = standardize_tensor(sales_on_monday)\n",
        "standardize_tensor_day"
      ],
      "metadata": {
        "id": "I66hYN8o3lVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine with the key (<q, k.T>)\n",
        "wednesday_sales = sales_on_wednesday_vector.matmul(sales_matrix_standardized.T)\n",
        "wednesday_sales"
      ],
      "metadata": {
        "id": "67wQyMucxUab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_matrix"
      ],
      "metadata": {
        "id": "-4eEMXfIx20s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Softmax on the sales (not so blown out! ... once the values were standardized)\n",
        "wednesday_sales = F.softmax(wednesday_sales, dim=0)\n",
        "wednesday_sales"
      ],
      "metadata": {
        "id": "z0BQ9phtxUX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale on the sales\n",
        "wednesday_sales = wednesday_sales/torch.sqrt(torch.tensor(wednesday_sales.shape[0]))\n",
        "wednesday_sales"
      ],
      "metadata": {
        "id": "oov-red4ysd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiply by the value to get the attention\n",
        "attention_to_pay_on_wednesdays = wednesday_sales @ price_vector_standardized\n",
        "attention_to_pay_on_wednesdays"
      ],
      "metadata": {
        "id": "J_rEK_5ExUVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price_vector_standardized"
      ],
      "metadata": {
        "id": "LjUzl-C0x6I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "each_day = torch.eye(7)\n",
        "each_day_standardized = standardize_tensor(each_day)\n",
        "each_day, each_day_standardized"
      ],
      "metadata": {
        "id": "4OV9D0bVzLET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention to pay each day\n",
        "each_day = torch.ones((7))\n",
        "\n",
        "def attention(query, key, value):\n",
        "  d_k = torch.tensor(query.shape[-1]) # torch.sqrt needs a tensor\n",
        "  print(d_k)\n",
        "  q_k = F.softmax(torch.matmul(query, key.T)/torch.sqrt(d_k), dim=-1)\n",
        "  print(q_k.shape)\n",
        "  return torch.matmul(q_k, value)\n",
        "\n",
        "attention(query=each_day_standardized,\n",
        "          key=sales_matrix_standardized,\n",
        "          value=price_vector_standardized)"
      ],
      "metadata": {
        "id": "kl-IsEFVzK5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention to pay each day\n",
        "monday = torch.zeros(7)\n",
        "monday[0] = 1\n",
        "monday_standardized = standardize_tensor(monday)\n",
        "print(monday)\n",
        "print(monday_standardized)\n",
        "\n",
        "def attention(query, key, value):\n",
        "  d_k = torch.tensor(query.shape[-1]) # torch.sqrt needs a tensor\n",
        "  print(d_k)\n",
        "  q_k = F.softmax(torch.matmul(query, key.T)/torch.sqrt(d_k), dim=-1)\n",
        "  print(q_k.shape)\n",
        "  return torch.matmul(q_k, value)\n",
        "\n",
        "attention(query=monday_standardized,\n",
        "          key=sales_matrix_standardized,\n",
        "          value=price_vector_standardized)"
      ],
      "metadata": {
        "id": "pX_UFBsf5hOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UPTOHERE\n",
        "# NEXT: clean up all of the above so it makes sense... in a bit of a mess now\n",
        "# Less but better..."
      ],
      "metadata": {
        "id": "xpMubs4O5r0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kt5_dUGp5hG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "boXf5xSb1VJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query = day of week\n",
        "# key = sales per day\n",
        "# value = prices of products\n",
        "# result/output = value of total products sold on target day (how much attention to pay to a certain day)\n",
        "\n",
        "# TK - if you wanted to get more information, you could increase the cafe sales to (52, 7) -> sales per day for 52 weeks in a year\n",
        "# -> or (5, 52, 7) (year, weeks, days) -> sales per day per week for 5 years\n",
        "\n",
        "# TODO:\n",
        "\n",
        "# How does this relate to attention?\n",
        "\n",
        "# At a large enough scale, you can do this for words in sentences.\n",
        "# For example, say we have 100 sentences.\n",
        "# Which words mean the most to which other words?\n",
        "# In a small sample like this, you might be able to design fixed values (like our coffee shop for different products).\n",
        "# But with a larger scale, you might have to design different values for different contexts.\n",
        "# The analogy being in a coffee shop in Australia, your pricing and products might be different to a coffee shop in Africa.\n",
        "# With a large enough corpus of words, having fixed values isn't going to work.\n",
        "# But the principle remains, how important is each other word to another word in a sentence?\n",
        "# What should you do?\n",
        "# Well, you'd never have time to assign a value for each word across a huge corpus.\n",
        "# So you can make the values for each word learnable.\n",
        "# Much like you might adjust your cafe prices and sales events given different days of the week.\n",
        "# The sales on Monday are very low (zero) because your cafe is closed on Monday.\n",
        "# Your customers don't assign much money (or attention) to your cafe on Monday's since they know it's closed.\n",
        "# Much like the attention score for the word \"cat\" might be very low in comparison to the word \"sodium metabisulfite\" because the two hardly ever occur in context of each other.\n",
        "\n",
        "# Why self-attention?\n",
        "\n",
        "# Applying the mechanism to itself over and over for different sequences enables the system to learn from the data itself.\n",
        "# As in, what words keep on showing up in the context of other words?\n",
        "# The dot product/matrix multiplication will amplify larger values.\n",
        "# In essence, given the query \"dog\" and the key of every word in the vocabulary, hopefully the model will learn to return \"cat\" as a likely value and \"sodium metabisulfite\" as a less likely value."
      ],
      "metadata": {
        "id": "7Y5OVpaQ8qJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5mVfO_5m8qFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO: Simple scaled-dot-product-attention (with mask)\n",
        "\n",
        "Next:\n",
        "- Read through GPT-from-scratch again\n",
        "- Read through Facebook's xformers\n",
        "- Read through Transformers from scratch blog post\n",
        "\n",
        "--\n",
        "\n",
        "* see: https://jaykmody.com/blog/gpt-from-scratch/#causal\n",
        "* And see: https://github.com/facebookresearch/xformers/blob/main/xformers/components/attention/attention_mask.py\n",
        "  * Default to causal mask: https://github.com/facebookresearch/xformers/blob/97daac83cece6d3d77bb09479777ad6e8ef7dfed/xformers/components/attention/attention_mask.py#LL74C16-L74C16 (`make_causal()`)"
      ],
      "metadata": {
        "id": "2xKawhtOcYfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make causal mask, see: https://jaykmody.com/blog/gpt-from-scratch/#causal\n",
        "additive_mask = torch.triu(\n",
        "    # torch.ones(x.shape[0], x.shape[0]) * float(\"inf\"),\n",
        "    torch.ones(x.shape[0], x.shape[0]) * -1e10, # can use -1e10 to prevent nans\n",
        "    diagonal=1\n",
        ")\n",
        "\n",
        "additive_mask"
      ],
      "metadata": {
        "id": "-66nS-Rdp0ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def attention_with_mask(query, key, value, mask=None):\n",
        "  d_k = torch.tensor(query.shape[-1]) # torch.sqrt needs a tensor\n",
        "  q_k = torch.matmul(query, key.T) / torch.sqrt(d_k)\n",
        "  print(q_k.shape)\n",
        "\n",
        "\n",
        "  print(f\"q_k: {q_k}\")\n",
        "\n",
        "  # Apply attention mask\n",
        "  if mask is not None:\n",
        "    q_k = q_k + mask\n",
        "\n",
        "  print(f\"q_k with mask: {q_k}\")\n",
        "\n",
        "  # Softmax\n",
        "  attn = F.softmax(q_k, dim=-1)\n",
        "\n",
        "  return torch.matmul(attn, value), attn\n",
        "\n",
        "attention_with_mask(query=x, key=x, value=x, mask=additive_mask)"
      ],
      "metadata": {
        "id": "MJcxus6qcYRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO: Why scaled?\n",
        "\n",
        "TL;DR softmax can get out of hand with large values"
      ],
      "metadata": {
        "id": "Y-c_uyAVUDzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "small_values = torch.tensor([1, 2, 3], dtype=torch.float32) # need dtype otherwise error\n",
        "big_values = small_values * 10\n",
        "huge_values = big_values * 10\n",
        "\n",
        "small_softmax = F.softmax(small_values, dim=0)\n",
        "big_softmax = F.softmax(big_values, dim=0)\n",
        "huge_softmax = F.softmax(huge_values, dim=0)\n",
        "\n",
        "print(f\"Small values: {small_values}\\nSmall softmax: {small_softmax}\\n\")\n",
        "print(f\"Big values: {big_values}\\nBig softmax: {big_softmax}\\n\")\n",
        "print(f\"Huge values: {huge_values}\\nHuge softmax: {huge_softmax}\\n\")"
      ],
      "metadata": {
        "id": "Z9ZRWyJTUJUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO: Why dot-product?\n",
        "\n",
        "TL;DR dot product measures how closely two vectors are related\n",
        "\n",
        "* big values = close\n",
        "* negative values = far away\n",
        "* zero value = same direction? (TK - fix this)\n",
        "\n",
        "See:\n",
        "* 3blue1brown on dot product - https://www.youtube.com/watch?v=LyGKycYT2v0"
      ],
      "metadata": {
        "id": "lQV-oF1SUm8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_1 = torch.arange(0, 1, 0.1)\n",
        "vector_2 = torch.ones_like(vector_1) / 10\n",
        "vector_3 = vector_1 - 0.1\n",
        "vector_4 = -vector_1\n",
        "print(vector_2)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(vector_1, label=\"vector_1\")\n",
        "plt.plot(vector_2, label=\"vector_2\")\n",
        "plt.plot(vector_3, label=\"vector_3\")\n",
        "plt.plot(vector_4, label=\"vector_4\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "hw3orswBU-GF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_sim = nn.CosineSimilarity(dim=0)\n",
        "cosine_sim(vector_1, vector_1)"
      ],
      "metadata": {
        "id": "btLpmYjjnzqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.dot(vector_1, vector_1)"
      ],
      "metadata": {
        "id": "wt1GW6VDm-Bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.dot(vector_1, vector_2)"
      ],
      "metadata": {
        "id": "RUpB8NIcmksx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.dot(vector_1, vector_3)"
      ],
      "metadata": {
        "id": "MhCy5erUmnFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.dot(vector_2, vector_3)"
      ],
      "metadata": {
        "id": "FJiwFLoKmuvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.dot(vector_1, vector_4)"
      ],
      "metadata": {
        "id": "1OWoPXzgm4Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sales example (total sales on Wednesday)\n",
        "torch.dot(price_vector, sales_matrix[:, 2])"
      ],
      "metadata": {
        "id": "Ok_hMVtpoVRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Same as taking the multiple and then summing them\n",
        "torch.sum(price_vector * df[\"Wednesday\"].values, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "rMiVEvINo_3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compresses the information into a single number\n",
        "cosine_sim(price_vector, price_vector)"
      ],
      "metadata": {
        "id": "5j6vCJcoolV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.dot(price_vector, price_vector)"
      ],
      "metadata": {
        "id": "AqpIVmJjqF-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO: Replicate PyTorch's `scaled_dot_product_attention`\n",
        "\n",
        "(minus all the fancy optimizations, the library can do those for us)\n",
        "\n",
        "See: https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html\n",
        "\n",
        "Also see: https://github.com/facebookresearch/xformers/blob/main/xformers/components/attention/core.py#L297"
      ],
      "metadata": {
        "id": "Mi9DKRGiOQJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally use the context manager to ensure one of the fused kerenels is run\n",
        "torch.manual_seed(42)\n",
        "\n",
        "query = torch.rand(32, 8, 128, 64) # [batch_size, num_heads, sequence_length, embedding_dim]\n",
        "key = torch.rand(32, 8, 128, 64)\n",
        "value = torch.rand(32, 8, 128, 64)\n"
      ],
      "metadata": {
        "id": "_JdMr4Jbshcu"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_pytorch = F.scaled_dot_product_attention(query, key, value)\n",
        "print(output_pytorch.shape)\n",
        "print(output_pytorch[0, 0, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDOCXshXQPxA",
        "outputId": "625d1bf1-d2c2-4809-9c73-5f451dfa2609"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 8, 128, 64])\n",
            "tensor([0.5430, 0.5479, 0.5143, 0.4744, 0.5149, 0.4867, 0.5063, 0.5088, 0.4863,\n",
            "        0.4620, 0.4989, 0.5488, 0.4746, 0.4955, 0.5334, 0.4886, 0.5158, 0.5267,\n",
            "        0.5183, 0.5251, 0.4939, 0.5092, 0.5408, 0.4267, 0.4645, 0.5221, 0.5587,\n",
            "        0.4917, 0.5142, 0.4762, 0.4839, 0.4837, 0.4937, 0.4671, 0.4898, 0.5195,\n",
            "        0.4942, 0.4938, 0.4783, 0.4796, 0.5454, 0.4686, 0.5112, 0.5717, 0.5081,\n",
            "        0.4588, 0.5151, 0.4970, 0.4649, 0.5143, 0.5019, 0.5053, 0.4928, 0.5278,\n",
            "        0.5332, 0.5121, 0.4882, 0.4992, 0.5197, 0.4865, 0.5028, 0.4908, 0.4975,\n",
            "        0.4808])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Does this have learnable parameters?\n",
        "output_pytorch.requires_grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjsviaZhkaU5",
        "outputId": "43eb4213-398f-4020-f5cd-e40e2e867b63"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def attention(query, key, value):\n",
        "  d_k = torch.tensor(query.shape[-1]) # torch.sqrt needs a tensor\n",
        "  print(torch.matmul(query, key.mT).shape)\n",
        "  print(key.mT.shape)\n",
        "  print(key.transpose(-2, -1).shape)\n",
        "\n",
        "  # tensor.mT is equivalent to tensor.transpose(-2, -1), see: https://pytorch.org/docs/stable/tensors.html#torch.Tensor.mT\n",
        "  # -> last two dimensions reversed\n",
        "  q_k = F.softmax(torch.matmul(query, key.mT)/torch.sqrt(d_k), dim=-1)\n",
        "\n",
        "  print(d_k)\n",
        "\n",
        "  print(d_k.shape, q_k.shape, value.shape)\n",
        "  print(q_k.shape, value.mT.shape)\n",
        "\n",
        "  return torch.matmul(q_k, value)\n",
        "\n",
        "output_custom = attention(query, key, value)\n",
        "print(output_pytorch.shape)\n",
        "# print(output_pytorch[0, 0, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4j-VvKEpZVI",
        "outputId": "80ad0107-0cd5-471d-b81c-f374e3bf3a6f"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 8, 128, 128])\n",
            "torch.Size([32, 8, 64, 128])\n",
            "torch.Size([32, 8, 64, 128])\n",
            "tensor(64)\n",
            "torch.Size([]) torch.Size([32, 8, 128, 128]) torch.Size([32, 8, 128, 64])\n",
            "torch.Size([32, 8, 128, 128]) torch.Size([32, 8, 64, 128])\n",
            "torch.Size([32, 8, 128, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assert all of the output values are close\n",
        "assert torch.all(output_custom.isclose(output_pytorch))"
      ],
      "metadata": {
        "id": "axD45MIHpO3y"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO: Why \"self\" attention\n",
        "\n",
        "TL;DR given a sequence, which parts of the sequence are most important based on the sequence itself\n",
        "\n",
        "Self-attention = based on its own input how should its representation differ\n",
        "\n",
        "Eg the word “cup” should have a different representation given the sentences:\n",
        "\n",
        "* “England won the World Cup”\n",
        "* “I filled my cup with orange juice”\n",
        "\n",
        "Same word, but different contexts - self-attention will adjust the weight values given the other items in the context."
      ],
      "metadata": {
        "id": "xdMSi7b2Xtgw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO: Make it learnable\n",
        "\n",
        "* TK - make this section more clear\n",
        "* TK - see section 3.2.2 Multi-Head Attention for \"where the **projections** are parameter matrics `WQ`, `WK`, `WV` etc\n",
        "  * Projections = learnable embedding = linear projection\n",
        "\n",
        "Okay cool, we've replicated PyTorch's `scaled_dot_product_attention`.\n",
        "\n",
        "But right now it's just a static operaton.\n",
        "\n",
        "And the whole goal of machine learning is to write algortihms that *learn* over time.\n",
        "\n",
        "So we need to make a learnable version of attention mechansim.\n",
        "\n",
        "How?\n",
        "\n",
        "Projections!\n",
        "\n",
        "What?\n",
        "\n",
        "Projections into embedding space.\n",
        "\n",
        "An embedding is a learnable representation of something.\n",
        "\n",
        "And so instead of a static vector representing our data, we can turn it into an embedding and create a *learnable vector* (a vector that changes over time given new information)."
      ],
      "metadata": {
        "id": "TSuilD4enBZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttentionLearnable(nn.Module):\n",
        "  def __init__(self, embed_dim):\n",
        "    super().__init__()\n",
        "    self.embed_dim = embed_dim\n",
        "    self.scale = embed_dim ** -0.5 # power of -0.5 == same as square root\n",
        "\n",
        "    # TK - one option = make one big projection (e.g. embed_dim * 3), then reshape = faster (on bigger GPUs)\n",
        "    # TK - another option = make one projection per Q, K, V\n",
        "\n",
        "    # Create a projection (learnable embedding)\n",
        "    self.qkv = nn.Linear(in_features=embed_dim,\n",
        "                         out_features=embed_dim * 3, # one per Q, K, V\n",
        "                         bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B, N, _ = x.shape\n",
        "\n",
        "    # Do the projection\n",
        "    qkv = self.qkv(x)\n",
        "    print(f\"qkv shape: {qkv.shape}\")\n",
        "\n",
        "    # qkv = qkv.reshape(B, N, 3, self.embed_dim).permute(1, # qkv\n",
        "    #                                                    0, # batch\n",
        "    #                                                    2, # num_tokens\n",
        "    #                                                    3) # embed_dim\n",
        "\n",
        "    qkv = qkv.reshape(B, N, 3, self.embed_dim).permute(2, # qkv\n",
        "                                                       0, # batch\n",
        "                                                       1, # num_tokens\n",
        "                                                       3) # embed_dim\n",
        "\n",
        "    print(f\"qkv shape: {qkv.shape}\")\n",
        "\n",
        "    # TODO: replace the above with einops?\n",
        "\n",
        "    q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "    print(f\"q shape: {q.shape} | k shape: {k.shape} | v shape: {v.shape}\")\n",
        "\n",
        "    # Perform self-attention (self = the operation happens on itself)\n",
        "    q_k = torch.matmul(q, k.mT)\n",
        "    print(f\"q_k shape: {q_k.shape}\")\n",
        "\n",
        "    q_k_scale = q_k * self.scale\n",
        "\n",
        "    # Softmax on embedding dim (last dim)\n",
        "    q_k_scale_softmax = torch.softmax(q_k_scale, dim=-1)\n",
        "\n",
        "    # Pefrom final batch mm\n",
        "    q_k_scale_softmax_v = torch.matmul(q_k_scale_softmax, v)\n",
        "\n",
        "    print(f\"q_k_scale_softmax_v output shape: {q_k_scale_softmax_v.shape}\")\n",
        "\n",
        "    # TODO: Try this with einops rearrange\n",
        "    x = q_k_scale_softmax_v.transpose(1, 2).reshape(B, N, self.embed_dim)\n",
        "\n",
        "    print(f\"x output shape: {x.shape}\")\n",
        "\n",
        "    return x\n",
        "\n",
        "embed_dim = 512\n",
        "batch_size = 32\n",
        "num_tokens = 128\n",
        "attention_learnable = SelfAttentionLearnable(embed_dim=embed_dim)\n",
        "x = torch.arange(batch_size*num_tokens*embed_dim, dtype=torch.float32).reshape(batch_size, num_tokens, embed_dim)\n",
        "print(f\"x input shape: {x.shape}\")\n",
        "x_out = attention_learnable(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWfQxB2jnBNi",
        "outputId": "c12c485b-d573-4f0f-9d32-96dd72c3a830"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x input shape: torch.Size([32, 128, 512])\n",
            "qkv shape: torch.Size([32, 128, 1536])\n",
            "qkv shape: torch.Size([3, 32, 128, 512])\n",
            "q shape: torch.Size([32, 128, 512]) | k shape: torch.Size([32, 128, 512]) | v shape: torch.Size([32, 128, 512])\n",
            "q_k shape: torch.Size([32, 128, 128])\n",
            "q_k_scale_softmax_v output shape: torch.Size([32, 128, 512])\n",
            "x output shape: torch.Size([32, 128, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now try learnable attention with einops..."
      ],
      "metadata": {
        "id": "mluQ_7rIzI8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What about einops?\n",
        "!pip install einops"
      ],
      "metadata": {
        "id": "0vp07fMCzMxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from einops import rearrange, reduce, repeat"
      ],
      "metadata": {
        "id": "RMSsOgyxzaVN"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttentionLearnable(nn.Module):\n",
        "  def __init__(self, embed_dim):\n",
        "    super().__init__()\n",
        "    self.embed_dim = embed_dim\n",
        "    self.scale = embed_dim ** -0.5 # power of -0.5 == same as square root\n",
        "\n",
        "    # Create a projection (learnable embedding) for each input (x -> Q, K, V)\n",
        "    self.q_projection = nn.Linear(in_features=embed_dim,\n",
        "                                  out_features=embed_dim,\n",
        "                                  bias=False)\n",
        "\n",
        "    self.k_projection = nn.Linear(in_features=embed_dim,\n",
        "                                  out_features=embed_dim,\n",
        "                                  bias=False)\n",
        "\n",
        "    self.v_projection = nn.Linear(in_features=embed_dim,\n",
        "                                  out_features=embed_dim,\n",
        "                                  bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B, N, _ = x.shape\n",
        "\n",
        "    # Do the projection(s)\n",
        "    q = self.q_projection(x)\n",
        "    k = self.k_projection(x)\n",
        "    v = self.v_projection(x)\n",
        "\n",
        "    print(f\"q shape: {q.shape} | k shape: {k.shape} | v shape: {v.shape}\")\n",
        "\n",
        "    # Perform self-attention (self = the operation happens on itself)\n",
        "    q_k = torch.matmul(q, k.mT)\n",
        "    print(f\"q_k shape: {q_k.shape}\")\n",
        "\n",
        "    q_k_scale = q_k * self.scale\n",
        "\n",
        "    # Softmax on embedding dim (last dim)\n",
        "    q_k_scale_softmax = torch.softmax(q_k_scale, dim=-1)\n",
        "\n",
        "    # Pefrom final batch mm\n",
        "    q_k_scale_softmax_v = torch.matmul(q_k_scale_softmax, v)\n",
        "\n",
        "    print(f\"q_k_scale_softmax_v output shape: {q_k_scale_softmax_v.shape}\")\n",
        "\n",
        "    # # TODO: Try this with einops rearrange\n",
        "    # x = q_k_scale_softmax_v.transpose(1, 2).reshape(B, N, self.embed_dim)\n",
        "\n",
        "    print(f\"x output shape: {x.shape}\")\n",
        "\n",
        "    return x\n",
        "\n",
        "embed_dim = 512\n",
        "batch_size = 32\n",
        "num_tokens = 128\n",
        "attention_learnable = SelfAttentionLearnable(embed_dim=embed_dim)\n",
        "x = torch.arange(batch_size*num_tokens*embed_dim, dtype=torch.float32).reshape(batch_size, num_tokens, embed_dim)\n",
        "print(f\"x input shape: {x.shape}\")\n",
        "x_out = attention_learnable(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxH9hueBzNLJ",
        "outputId": "f95ad63d-bf83-44da-8fe8-1e02fe68dad8"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x input shape: torch.Size([32, 128, 512])\n",
            "q shape: torch.Size([32, 128, 512]) | k shape: torch.Size([32, 128, 512]) | v shape: torch.Size([32, 128, 512])\n",
            "q_k shape: torch.Size([32, 128, 128])\n",
            "q_k_scale_softmax_v output shape: torch.Size([32, 128, 512])\n",
            "x output shape: torch.Size([32, 128, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UPTOHERE:\n",
        "# Replace forward() with F.scaled_dot_product_attention...\n",
        "# by the end you should know the attention formula off by heart (it's not too hard... a few variables + a few operations), getting the shapes to line up is the hard part"
      ],
      "metadata": {
        "id": "0WGbzrk91Q1N"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttentionLearnableCustom(nn.Module):\n",
        "  def __init__(self, embed_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.embed_dim = embed_dim\n",
        "\n",
        "    # Create scale\n",
        "    self.scale = embed_dim ** -0.5\n",
        "\n",
        "    # Create projections\n",
        "    self.query_projection = nn.Linear(in_features=embed_dim,\n",
        "                                      out_features=embed_dim,\n",
        "                                      bias=False)\n",
        "\n",
        "    self.key_projection = nn.Linear(in_features=embed_dim,\n",
        "                                    out_features=embed_dim,\n",
        "                                    bias=False)\n",
        "\n",
        "    self.value_projection = nn.Linear(in_features=embed_dim,\n",
        "                                      out_features=embed_dim,\n",
        "                                      bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    query, key, value = self.query_projection(x), self.key_projection(x), self.value_projection(x)\n",
        "\n",
        "    # Perform scaled_dot_production_attention\n",
        "    attn = attention(query=query,\n",
        "                     key=key,\n",
        "                     value=value)\n",
        "\n",
        "    return attn"
      ],
      "metadata": {
        "id": "yl2estiVb9ht"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttentionLearnablePyTorch(nn.Module):\n",
        "  def __init__(self, embed_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.embed_dim = embed_dim\n",
        "\n",
        "    # Create scale\n",
        "    self.scale = embed_dim ** -0.5\n",
        "\n",
        "    # Create projections\n",
        "    self.query_projection = nn.Linear(in_features=embed_dim,\n",
        "                                      out_features=embed_dim,\n",
        "                                      bias=False)\n",
        "\n",
        "    self.key_projection = nn.Linear(in_features=embed_dim,\n",
        "                                    out_features=embed_dim,\n",
        "                                    bias=False)\n",
        "\n",
        "    self.value_projection = nn.Linear(in_features=embed_dim,\n",
        "                                      out_features=embed_dim,\n",
        "                                      bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    query, key, value = self.query_projection(x), self.key_projection(x), self.value_projection(x)\n",
        "\n",
        "    # Perform scaled_dot_production_attention\n",
        "    attn = F.scaled_dot_product_attention(query=query,\n",
        "                                          key=key,\n",
        "                                          value=value)\n",
        "\n",
        "    return attn"
      ],
      "metadata": {
        "id": "tETWkPQRYOiU"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the outcomes are the same\n",
        "\n",
        "torch.manual_seed(42)\n",
        "self_attention_custom = SelfAttentionLearnableCustom(embed_dim=512)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "self_attention_pytorch = SelfAttentionLearnablePyTorch(embed_dim=512)\n",
        "\n",
        "x = torch.arange(batch_size*num_tokens*embed_dim, dtype=torch.float32).reshape(batch_size, num_tokens, embed_dim)\n",
        "print(f\"x input shape: {x.shape}\")\n",
        "\n",
        "x_out_custom = self_attention_custom(x)\n",
        "\n",
        "x_out_pytorch = self_attention_pytorch(x)\n",
        "x_out_custom.shape, x_out_pytorch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU9lDyWtaIGQ",
        "outputId": "7a8dc2ac-c540-4010-c96b-d313c9e65cc3"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x input shape: torch.Size([32, 128, 512])\n",
            "torch.Size([32, 128, 128])\n",
            "torch.Size([32, 512, 128])\n",
            "torch.Size([32, 512, 128])\n",
            "tensor(512)\n",
            "torch.Size([]) torch.Size([32, 128, 128]) torch.Size([32, 128, 512])\n",
            "torch.Size([32, 128, 128]) torch.Size([32, 512, 128])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 128, 512]), torch.Size([32, 128, 512]))"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_out_pytorch[0][0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7vRLOBwc0si",
        "outputId": "e8d07a50-c096-4042-a72a-961cf4201564"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(104.0217, grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_out_custom[0][0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eryYLIGacxut",
        "outputId": "73fa12ff-6450-4c03-e101-cc73b3f17bb9"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(104.0217, grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.all(x_out_custom.isclose(x_out_pytorch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpkbkprHcYOZ",
        "outputId": "5f3bcd12-bb62-4463-aef6-9c480bb81fea"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO: A cool trick with `einops`"
      ],
      "metadata": {
        "id": "71vKVcG4l54t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What about einops?\n",
        "!pip install einops"
      ],
      "metadata": {
        "id": "cZrCXRCQucfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from einops import rearrange, reduce, repeat\n",
        "\n",
        "print(f\"Key shape: {key.shape} [batch, num_heads, input_sequence, embedding_dim]\")\n",
        "\n",
        "### The following all do the same ###\n",
        "\n",
        "# Rearrange the shape for our use case\n",
        "key_rearranged = rearrange(key, 'batch heads input embed -> batch heads embed input')\n",
        "\n",
        "# Key tranposed\n",
        "key_transposed = key.transpose(-2, -1)\n",
        "\n",
        "# Key mT (note: use .mT rather than .T on tensors with more than two dimensions)\n",
        "key_mt = key.mT\n",
        "\n",
        "print(key_rearranged.shape, key_transposed.shape, key_mt.shape)\n",
        "assert key_rearranged.shape == key_transposed.shape == key_mt.shape"
      ],
      "metadata": {
        "id": "QWU9f--huvnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO: Why multi-head attention?\n",
        "\n",
        "TL;DR more opportunities to learn (e.g. 8x64 scaled dot-product attention = better than 1*512)\n",
        "\n",
        "TK:\n",
        "- One big matrix multiplication better than lots of small ones\n",
        "- Just perform a `nn.Linear()` then break it up\n",
        "- Implementing multi-head attention gives you self-attention, because you just use 1 head (versus multiple)\n",
        "\n",
        "**Goal:** Replicate PyTorch's `torch.nn.MultiheadAttention()` - https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html"
      ],
      "metadata": {
        "id": "81KIT2MtYKyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multi_head_attention_pytorch = torch.nn.MultiheadAttention(embed_dim=512,\n",
        "                                                           num_heads=8,\n",
        "                                                           batch_first=True, # Does your batch dimension come first?\n",
        "                                                           )\n",
        "\n",
        "attn_output, attn_output_weights = multi_head_attention_pytorch(query=x, key=x, value=x,\n",
        "                                                                need_weights=True) # Return weights or not\n",
        "x.shape, attn_output.shape, attn_output_weights.shape"
      ],
      "metadata": {
        "id": "InUnaU5hYY4i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f001e52-22e1-42f6-eff0-f9ec2c687065"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 128, 512]),\n",
              " torch.Size([32, 128, 512]),\n",
              " torch.Size([32, 128, 128]))"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_output.requires_grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeGA5DWonxm5",
        "outputId": "dee96b03-9a59-4f15-ea9f-44c980b248c1"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TK - embed_dim, num_heads = minimum viable variables (masking can come later)\n",
        "class MultiheadAttentionCustom(nn.Module):\n",
        "  def __init__(self,\n",
        "               embed_dim,\n",
        "               num_heads,\n",
        "               # TK - dropout\n",
        "               ):\n",
        "    super().__init__()\n",
        "    self.embed_dim = embed_dim\n",
        "    self.num_heads = num_heads\n",
        "\n",
        "    assert embed_dim % num_heads == 0, \"Embedding dimension must be divisible by number of heads\"\n",
        "\n",
        "    self.head_dim = embed_dim // num_heads\n",
        "    self.scale = self.head_dim ** -0.5 # \"to the power\" is same as squareroot\n",
        "\n",
        "    self.softmax = nn.Softmax(dim=-1) # perform softmax on embedding dim (last dim)\n",
        "\n",
        "    # TK - see bias parameter in docs: https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html\n",
        "    # \"bias – If specified, adds bias to input / output projection layers. Default: True.\"\n",
        "    self.query_projection = nn.Linear(embed_dim, embed_dim, bias=True)\n",
        "    self.key_projection = nn.Linear(embed_dim, embed_dim, bias=True)\n",
        "    self.value_projection = nn.Linear(embed_dim, embed_dim, bias=True)\n",
        "\n",
        "    # Project out\n",
        "    self.project_out = nn.Linear(embed_dim, embed_dim, bias=True)\n",
        "\n",
        "    # TODO: dropout\n",
        "    # TODO: masking\n",
        "\n",
        "  def forward(self, x):\n",
        "    batch_size, num_tokens, embed_dim = x.shape\n",
        "\n",
        "    # Project_in (linear)\n",
        "    query, key, value = self.query_projection(x), self.key_projection(x), self.value_projection(x)\n",
        "\n",
        "    print(f\"Query shape: {query.shape} | Key shape: {key.shape} | Value shape: {value.shape}\")\n",
        "\n",
        "    # Convert to num heads\n",
        "    query = query.reshape(batch_size, num_tokens, self.num_heads, self.head_dim)\n",
        "    key = key.reshape(batch_size, num_tokens, self.num_heads, self.head_dim)\n",
        "    value = value.reshape(batch_size, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "    print(f\"Query shape (heads): {query.shape} | Key shape (heads): {key.shape} | Value shape (heads): {value.shape}\")\n",
        "\n",
        "    # self-attention * heads = softmax((<q, k>)/d_k))v\n",
        "    dots = torch.matmul(query, key.mT) * self.scale\n",
        "    attn = self.softmax(dots)\n",
        "    out = torch.matmul(attn, value)\n",
        "\n",
        "    print(f\"Out shape: {out.shape}\")\n",
        "\n",
        "    # TODO: dropout\n",
        "\n",
        "    # Concat last two dims together\n",
        "    concat = out.reshape(batch_size, num_tokens, embed_dim)\n",
        "    print(f\"Concat shape: {concat.shape}\")\n",
        "\n",
        "    # project_out (linear)\n",
        "    x_out = self.project_out(concat)\n",
        "    print(f\"Projection out shape: {x_out.shape}\")\n",
        "\n",
        "    return x_out\n",
        "\n",
        "\n",
        "multihead_attention_custom = MultiheadAttentionCustom(embed_dim=512, num_heads=8)\n",
        "x_multihead_out_custom = multihead_attention_custom(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9E0YNtvgZpa",
        "outputId": "60cddc76-f04f-4a3e-e1f9-97f8c724e51f"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query shape: torch.Size([32, 128, 512]) | Key shape: torch.Size([32, 128, 512]) | Value shape: torch.Size([32, 128, 512])\n",
            "Query shape (heads): torch.Size([32, 128, 8, 64]) | Key shape (heads): torch.Size([32, 128, 8, 64]) | Value shape (heads): torch.Size([32, 128, 8, 64])\n",
            "Out shape: torch.Size([32, 128, 8, 64])\n",
            "Concat shape: torch.Size([32, 128, 512])\n",
            "Projection out shape: torch.Size([32, 128, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(batch_size*num_tokens*embed_dim, dtype=torch.float32).reshape(batch_size, num_tokens, embed_dim)\n",
        "print(f\"x input shape: {x.shape}\")\n",
        "\n",
        "torch.manual_seed(42)\n",
        "multi_head_attention_pytorch = torch.nn.MultiheadAttention(embed_dim=512,\n",
        "                                                           num_heads=8,\n",
        "                                                           batch_first=True, # Does your batch dimension come first?\n",
        "                                                           )\n",
        "\n",
        "\n",
        "torch.manual_seed(42)\n",
        "multihead_attention_custom = MultiheadAttentionCustom(embed_dim=512, num_heads=8)\n",
        "\n",
        "\n",
        "x_attn_output_pytorch, attn_output_weights = multi_head_attention_pytorch(query=x, key=x, value=x,\n",
        "                                                                need_weights=True) # Return weights or not\n",
        "\n",
        "x_multihead_out_custom = multihead_attention_custom(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcKRix-OrC7K",
        "outputId": "a43a2276-3f4a-4272-f790-354df10f8c91"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x input shape: torch.Size([32, 128, 512])\n",
            "Query shape: torch.Size([32, 128, 512]) | Key shape: torch.Size([32, 128, 512]) | Value shape: torch.Size([32, 128, 512])\n",
            "Query shape (heads): torch.Size([32, 128, 8, 64]) | Key shape (heads): torch.Size([32, 128, 8, 64]) | Value shape (heads): torch.Size([32, 128, 8, 64])\n",
            "Out shape: torch.Size([32, 128, 8, 64])\n",
            "Concat shape: torch.Size([32, 128, 512])\n",
            "Projection out shape: torch.Size([32, 128, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_attn_output_pytorch.shape), print(x_multihead_out_custom.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b8UOfBYsWhq",
        "outputId": "426e6b41-5ece-4f84-e778-f0e3110b3522"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 128, 512])\n",
            "torch.Size([32, 128, 512])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_attn_output_pytorch[0][0][0], x_multihead_out_custom[0][0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bexbdvBisu4a",
        "outputId": "5da08e1c-cc50-498e-ae5a-057d69eb4db7"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(16859.5352, grad_fn=<SelectBackward0>),\n",
              " tensor(-68.8901, grad_fn=<SelectBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TK - make sure these are close\n",
        "torch.all(x_attn_output_pytorch.isclose(x_multihead_out_custom))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UepiHy66s12i",
        "outputId": "81d96eaf-09df-4b65-b16a-82e6688ab3e6"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(False)"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next:\n",
        "# Go through attention = simple version\n",
        "# Go through attention -> replicate PyTorch scaled_dot_product_attention\n",
        "# Go through attention -> replicate masking\n",
        "# Make it learnable\n",
        "# Make it multi-head (multi-head can be the same as single head if you code it to be so...)"
      ],
      "metadata": {
        "id": "_JE4Bzkis858"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}